<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Logistic Regression | Machine Learning with TidyModels</title>
  <meta name="description" content="This is a primer on various ML modeling techniques and the tidymodels</code>
syntax and workflow for leveraging these techniques.</p>" />
  <meta name="generator" content="bookdown 0.29 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Logistic Regression | Machine Learning with TidyModels" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is a primer on various ML modeling techniques and the tidymodels</code>
syntax and workflow for leveraging these techniques.</p>" />
  <meta name="github-repo" content="ericwburden/machine-learning-with-tidymodels" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Logistic Regression | Machine Learning with TidyModels" />
  
  <meta name="twitter:description" content="This is a primer on various ML modeling techniques and the tidymodels</code>
syntax and workflow for leveraging these techniques.</p>" />
  

<meta name="author" content="Eric Burden" />


<meta name="date" content="2022-11-06" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="chapter-4.html"/>
<link rel="next" href="references.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; } /* Alert */
code span.an { color: #008000; } /* Annotation */
code span.at { } /* Attribute */
code span.bu { } /* BuiltIn */
code span.cf { color: #0000ff; } /* ControlFlow */
code span.ch { color: #008080; } /* Char */
code span.cn { } /* Constant */
code span.co { color: #008000; } /* Comment */
code span.cv { color: #008000; } /* CommentVar */
code span.do { color: #008000; } /* Documentation */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.im { } /* Import */
code span.in { color: #008000; } /* Information */
code span.kw { color: #0000ff; } /* Keyword */
code span.op { } /* Operator */
code span.ot { color: #ff4000; } /* Other */
code span.pp { color: #ff4000; } /* Preprocessor */
code span.sc { color: #008080; } /* SpecialChar */
code span.ss { color: #008080; } /* SpecialString */
code span.st { color: #008080; } /* String */
code span.va { } /* Variable */
code span.vs { color: #008080; } /* VerbatimString */
code span.wa { color: #008000; font-weight: bold; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Notes on Tidymodels</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> About</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#ch1-software_used"><i class="fa fa-check"></i><b>1.1</b> Software Used</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="chapter-2.html"><a href="chapter-2.html"><i class="fa fa-check"></i><b>2</b> The Tidymodels Workflow</a>
<ul>
<li class="chapter" data-level="2.1" data-path="chapter-2.html"><a href="chapter-2.html#ch2-about-tidymodels"><i class="fa fa-check"></i><b>2.1</b> About Tidymodels</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="chapter-2.html"><a href="chapter-2.html#ch2-reuse-existing-data-structures"><i class="fa fa-check"></i><b>2.1.1</b> Re-use existing data structures</a></li>
<li class="chapter" data-level="2.1.2" data-path="chapter-2.html"><a href="chapter-2.html#ch2-simple-functions-with-pipes"><i class="fa fa-check"></i><b>2.1.2</b> Compose simple functions with pipes</a></li>
<li class="chapter" data-level="2.1.3" data-path="chapter-2.html"><a href="chapter-2.html#ch2-embrace-functional-programming"><i class="fa fa-check"></i><b>2.1.3</b> Embrace functional programming</a></li>
<li class="chapter" data-level="2.1.4" data-path="chapter-2.html"><a href="chapter-2.html#ch2-design-for-humans"><i class="fa fa-check"></i><b>2.1.4</b> Design for humans</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="chapter-2.html"><a href="chapter-2.html#ch2-philosophy-in-practice"><i class="fa fa-check"></i><b>2.2</b> Philosophy in Practice</a></li>
<li class="chapter" data-level="2.3" data-path="chapter-2.html"><a href="chapter-2.html#ch2-workflow-steps"><i class="fa fa-check"></i><b>2.3</b> Workflow Steps</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="chapter-2.html"><a href="chapter-2.html#ch2-data-splitting"><i class="fa fa-check"></i><b>2.3.1</b> Data Splitting</a></li>
<li class="chapter" data-level="2.3.2" data-path="chapter-2.html"><a href="chapter-2.html#ch2-data-preparation"><i class="fa fa-check"></i><b>2.3.2</b> Data Preparation</a></li>
<li class="chapter" data-level="2.3.3" data-path="chapter-2.html"><a href="chapter-2.html#ch2-model-specification"><i class="fa fa-check"></i><b>2.3.3</b> Model Specification</a></li>
<li class="chapter" data-level="2.3.4" data-path="chapter-2.html"><a href="chapter-2.html#ch2-bundling-a-workflow"><i class="fa fa-check"></i><b>2.3.4</b> Bundling a Workflow</a></li>
<li class="chapter" data-level="2.3.5" data-path="chapter-2.html"><a href="chapter-2.html#ch2-checking-results"><i class="fa fa-check"></i><b>2.3.5</b> Checking Results</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="chapter-3.html"><a href="chapter-3.html"><i class="fa fa-check"></i><b>3</b> Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="3.1" data-path="chapter-3.html"><a href="chapter-3.html#ch3-description"><i class="fa fa-check"></i><b>3.1</b> Description</a></li>
<li class="chapter" data-level="3.2" data-path="chapter-3.html"><a href="chapter-3.html#ch3-how-it-works"><i class="fa fa-check"></i><b>3.2</b> How it Works</a></li>
<li class="chapter" data-level="3.3" data-path="chapter-3.html"><a href="chapter-3.html#ch3-evaluating-validity"><i class="fa fa-check"></i><b>3.3</b> Evaluating Validity</a></li>
<li class="chapter" data-level="3.4" data-path="chapter-3.html"><a href="chapter-3.html#ch3-evaluating-fit"><i class="fa fa-check"></i><b>3.4</b> Evaluating Fit</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="chapter-3.html"><a href="chapter-3.html#ch3-residual-standard-error"><i class="fa fa-check"></i><b>3.4.1</b> Residual Standard Error</a></li>
<li class="chapter" data-level="3.4.2" data-path="chapter-3.html"><a href="chapter-3.html#ch3-rsq-statistic"><i class="fa fa-check"></i><b>3.4.2</b> <span class="math inline">\(R^2\)</span> Statistic</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="chapter-3.html"><a href="chapter-3.html#ch3-example"><i class="fa fa-check"></i><b>3.5</b> Example</a></li>
<li class="chapter" data-level="3.6" data-path="chapter-3.html"><a href="chapter-3.html#ch3-considerations"><i class="fa fa-check"></i><b>3.6</b> Considerations</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="chapter-3.html"><a href="chapter-3.html#ch3-limits-of-applicability"><i class="fa fa-check"></i><b>3.6.1</b> Limits of Applicability</a></li>
<li class="chapter" data-level="3.6.2" data-path="chapter-3.html"><a href="chapter-3.html#ch3-outliers"><i class="fa fa-check"></i><b>3.6.2</b> Outliers</a></li>
<li class="chapter" data-level="3.6.3" data-path="chapter-3.html"><a href="chapter-3.html#ch3-high-leverage-points"><i class="fa fa-check"></i><b>3.6.3</b> High-leverage points</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="chapter-4.html"><a href="chapter-4.html"><i class="fa fa-check"></i><b>4</b> Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="4.1" data-path="chapter-4.html"><a href="chapter-4.html#ch4-description"><i class="fa fa-check"></i><b>4.1</b> Description</a></li>
<li class="chapter" data-level="4.2" data-path="chapter-4.html"><a href="chapter-4.html#ch4-how-it-works"><i class="fa fa-check"></i><b>4.2</b> How it Works</a></li>
<li class="chapter" data-level="4.3" data-path="chapter-4.html"><a href="chapter-4.html#ch4-evaluating-validity"><i class="fa fa-check"></i><b>4.3</b> Evaluating Validity</a></li>
<li class="chapter" data-level="4.4" data-path="chapter-4.html"><a href="chapter-4.html#ch4-identifying-important-predictors"><i class="fa fa-check"></i><b>4.4</b> Identifying Important Predictors</a></li>
<li class="chapter" data-level="4.5" data-path="chapter-4.html"><a href="chapter-4.html#ch4-evaluating-fit"><i class="fa fa-check"></i><b>4.5</b> Evaluating Fit</a></li>
<li class="chapter" data-level="4.6" data-path="chapter-4.html"><a href="chapter-4.html#ch4-example"><i class="fa fa-check"></i><b>4.6</b> Example</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="chapter-4.html"><a href="chapter-4.html#ch-correlated-predictors"><i class="fa fa-check"></i><b>4.6.1</b> Correlated Predictors</a></li>
<li class="chapter" data-level="4.6.2" data-path="chapter-4.html"><a href="chapter-4.html#ch4-tidymodels-workflow"><i class="fa fa-check"></i><b>4.6.2</b> Tidymodels Workflow</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="chapter-4.html"><a href="chapter-4.html#ch4-considerations"><i class="fa fa-check"></i><b>4.7</b> Considerations</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="chapter-4.html"><a href="chapter-4.html#ch4-not-just-combining-simple-models"><i class="fa fa-check"></i><b>4.7.1</b> Not Just Combining Simple Models</a></li>
<li class="chapter" data-level="4.7.2" data-path="chapter-4.html"><a href="chapter-4.html#ch4-qualitative-variables"><i class="fa fa-check"></i><b>4.7.2</b> Qualitative Variables</a></li>
<li class="chapter" data-level="4.7.3" data-path="chapter-4.html"><a href="chapter-4.html#ch4-predictor-interactions"><i class="fa fa-check"></i><b>4.7.3</b> Predictor Interactions</a></li>
<li class="chapter" data-level="4.7.4" data-path="chapter-4.html"><a href="chapter-4.html#ch4-polynomial-regression"><i class="fa fa-check"></i><b>4.7.4</b> Polynomial Regression</a></li>
<li class="chapter" data-level="4.7.5" data-path="chapter-4.html"><a href="chapter-4.html#ch4-potential-issues"><i class="fa fa-check"></i><b>4.7.5</b> Potential Issues</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="chapter-5.html"><a href="chapter-5.html"><i class="fa fa-check"></i><b>5</b> Logistic Regression</a>
<ul>
<li class="chapter" data-level="5.1" data-path="chapter-5.html"><a href="chapter-5.html#ch5-description"><i class="fa fa-check"></i><b>5.1</b> Description</a></li>
<li class="chapter" data-level="5.2" data-path="chapter-5.html"><a href="chapter-5.html#ch5-how-it-works"><i class="fa fa-check"></i><b>5.2</b> How it Works</a></li>
<li class="chapter" data-level="5.3" data-path="chapter-5.html"><a href="chapter-5.html#ch5-evaluating-validity"><i class="fa fa-check"></i><b>5.3</b> Evaluating Validity</a></li>
<li class="chapter" data-level="5.4" data-path="chapter-5.html"><a href="chapter-5.html#ch5-evaluating-fit"><i class="fa fa-check"></i><b>5.4</b> Evaluating Fit</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="chapter-5.html"><a href="chapter-5.html#ch5-binomial-logistic-regression"><i class="fa fa-check"></i><b>5.4.1</b> Binomial Logistic Regression</a></li>
<li class="chapter" data-level="5.4.2" data-path="chapter-5.html"><a href="chapter-5.html#ch5-multinomial-logistic-regression"><i class="fa fa-check"></i><b>5.4.2</b> Multinomial Logistic Regression</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="chapter-5.html"><a href="chapter-5.html#ch5-example"><i class="fa fa-check"></i><b>5.5</b> Example</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="chapter-5.html"><a href="chapter-5.html#dataset"><i class="fa fa-check"></i><b>5.5.1</b> Dataset</a></li>
<li class="chapter" data-level="5.5.2" data-path="chapter-5.html"><a href="chapter-5.html#response-categories"><i class="fa fa-check"></i><b>5.5.2</b> Response Categories</a></li>
<li class="chapter" data-level="5.5.3" data-path="chapter-5.html"><a href="chapter-5.html#correlations"><i class="fa fa-check"></i><b>5.5.3</b> Correlations</a></li>
<li class="chapter" data-level="5.5.4" data-path="chapter-5.html"><a href="chapter-5.html#high-leverage-points"><i class="fa fa-check"></i><b>5.5.4</b> High Leverage Points</a></li>
<li class="chapter" data-level="5.5.5" data-path="chapter-5.html"><a href="chapter-5.html#fit-and-check"><i class="fa fa-check"></i><b>5.5.5</b> Fit and Check</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>6</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Machine Learning with TidyModels</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="chapter-5" class="section level1 hasAnchor" number="5">
<h1><span class="header-section-number">Chapter 5</span> Logistic Regression<a href="chapter-5.html#chapter-5" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="ch5-description" class="section level2 hasAnchor" number="5.1">
<h2><span class="header-section-number">5.1</span> Description<a href="chapter-5.html#ch5-description" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>An approach for predicting a the probability that response value <span class="math inline">\(Y\)</span> belongs to a
particular <em>category</em> based on one or more predictor values <span class="math inline">\(X_1, X_2, ... X_n\)</span>. The
probability will always lie between 0 (no chance) and 1 (absolute certainty) and can be
given by the following <em>logistic function</em> for the case with a single predictor
variable:</p>
<p><span class="math display">\[p(X) = \frac{e^{\beta_0 + \beta_1X}}{1 + e^{\beta_0 + \beta_1X}}\]</span> where
<span class="math inline">\(p(X) = Pr(Y = category|X)\)</span>, which can be read as “the probability that <span class="math inline">\(Y\)</span> is
<code>category</code> given <span class="math inline">\(X\)</span>.</p>
<p>Unlike a linear function, this <em>logistic</em> function will not indicate a probability of an
observation belonging to a particular category as negative or greater than 1.
Determining whether to treat a particular observation as belonging to a particular
category can be made on the basis of the probability returned by this function. It may
be reasonable to use a 50% threshold in many cases (<span class="math inline">\(p(X) &gt; 0.5\)</span>), but an analyst may
want to be adjust this threshold to meet business needs. You may wish to raise the
threshold to reduce false positive classifications or lower it to reduce false negative
classifications.</p>
</div>
<div id="ch5-how-it-works" class="section level2 hasAnchor" number="5.2">
<h2><span class="header-section-number">5.2</span> How it Works<a href="chapter-5.html#ch5-how-it-works" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A careful observer may not some similarities in the exponents of the formula above and
the linear formula discussed in previous chapters. A bit of manipulation yields:</p>
<p><span class="math display">\[\frac{p(X)}{1 - p(X)} = e^{\beta_0 + \beta_1X}\]</span></p>
<p>where the <span class="math inline">\(\frac{p(X)}{1 - p(X)}\)</span> term is labeled as the <em>odds</em> of the event, such that
an <em>odds</em> of <span class="math inline">\(1/4\)</span> yields <span class="math inline">\(p(X) = 0.2\)</span> and an <em>odds</em> of <span class="math inline">\(9\)</span> yields <span class="math inline">\(p(X) = 0.9\)</span>. You can
confirm this by noting that <span class="math inline">\(\frac{0.9}{1 - 0.9} = 9\)</span>. Taking the logarithm of both
sides yields:</p>
<p><span class="math display">\[\ln{ \left( \frac{p(X)}{1 - p(X)} \right) } = \beta_0 + \beta_1X\]</span></p>
<p>The left-hand side of that equation is called the <em>log odds</em> or <em>logit</em>. Now, our
equation looks <em>eerily</em> similar to the linear equation because, in fact, the
relationship between “the log odds that the response falls into a certain category given
<span class="math inline">\(X\)</span>” and <span class="math inline">\(X\)</span> is linear. That is, for one unit change in <span class="math inline">\(X\)</span>, the log odds that the
response falls into the indicated category changes by a constant amount <span class="math inline">\(\beta_1\)</span>. This
behavior can be extended to the case of multiple predictor variables in a manner
analogous to what we have seen for <a href="chapter-4.html#chapter-4">Linear Regression</a>:</p>
<p><span class="math display">\[\ln{ \left( \frac{p(X)}{1 - p(X)} \right) } = \beta_0 + \beta_1x_1 + \,... \, + \beta_px_p\]</span></p>
<p>This model can also be extended to the case where there are more than two response
categories, known as a <em>multinomial logistic regression</em> model, like so (with a single
predictor for simplicity):</p>
<p><span class="math display">\[\ln{ \left( \frac{Pr(Y=k|X)}{Pr(Y=K|X)} \right) } = \beta_0 + \beta_1X\]</span> To do this,
given that there are <span class="math inline">\(K\)</span> possible values for <span class="math inline">\(Y\)</span>, one possible <span class="math inline">\(K\)</span> is chosen as the
default, or <em>baseline</em> value. Consider the example of a model to classify flower species
using the <code>iris</code> data set.</p>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="chapter-5.html#cb47-1" aria-hidden="true" tabindex="-1"></a>skimr<span class="sc">::</span><span class="fu">skim</span>(iris)</span></code></pre></div>
<table>
<caption><span id="tab:ch5-1">Table 5.1: </span>Data summary</caption>
<tbody>
<tr class="odd">
<td align="left">Name</td>
<td align="left">iris</td>
</tr>
<tr class="even">
<td align="left">Number of rows</td>
<td align="left">150</td>
</tr>
<tr class="odd">
<td align="left">Number of columns</td>
<td align="left">5</td>
</tr>
<tr class="even">
<td align="left">_______________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Column type frequency:</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">factor</td>
<td align="left">1</td>
</tr>
<tr class="odd">
<td align="left">numeric</td>
<td align="left">4</td>
</tr>
<tr class="even">
<td align="left">________________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Group variables</td>
<td align="left">None</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: factor</strong></p>
<table style="width:100%;">
<colgroup>
<col width="17%" />
<col width="12%" />
<col width="17%" />
<col width="9%" />
<col width="11%" />
<col width="32%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="left">ordered</th>
<th align="right">n_unique</th>
<th align="left">top_counts</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Species</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">FALSE</td>
<td align="right">3</td>
<td align="left">set: 50, ver: 50, vir: 50</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table style="width:100%;">
<colgroup>
<col width="18%" />
<col width="13%" />
<col width="18%" />
<col width="6%" />
<col width="6%" />
<col width="5%" />
<col width="5%" />
<col width="6%" />
<col width="5%" />
<col width="6%" />
<col width="7%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="right">p0</th>
<th align="right">p25</th>
<th align="right">p50</th>
<th align="right">p75</th>
<th align="right">p100</th>
<th align="left">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Sepal.Length</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">5.84</td>
<td align="right">0.83</td>
<td align="right">4.3</td>
<td align="right">5.1</td>
<td align="right">5.80</td>
<td align="right">6.4</td>
<td align="right">7.9</td>
<td align="left">▆▇▇▅▂</td>
</tr>
<tr class="even">
<td align="left">Sepal.Width</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">3.06</td>
<td align="right">0.44</td>
<td align="right">2.0</td>
<td align="right">2.8</td>
<td align="right">3.00</td>
<td align="right">3.3</td>
<td align="right">4.4</td>
<td align="left">▁▆▇▂▁</td>
</tr>
<tr class="odd">
<td align="left">Petal.Length</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">3.76</td>
<td align="right">1.77</td>
<td align="right">1.0</td>
<td align="right">1.6</td>
<td align="right">4.35</td>
<td align="right">5.1</td>
<td align="right">6.9</td>
<td align="left">▇▁▆▇▂</td>
</tr>
<tr class="even">
<td align="left">Petal.Width</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1.20</td>
<td align="right">0.76</td>
<td align="right">0.1</td>
<td align="right">0.3</td>
<td align="right">1.30</td>
<td align="right">1.8</td>
<td align="right">2.5</td>
<td align="left">▇▁▇▅▃</td>
</tr>
</tbody>
</table>
<p>If you are fitting a logistic regression to the <code>iris</code> data set to predict species, you
may set the <em>baseline</em> to be ‘virginica’. The choice of baseline is not important for
fitting the model, but it is important for interpreting the estimated <span class="math inline">\(\beta\)</span>
coefficients, as <span class="math inline">\(Pr(Y = k|X)\)</span> is read as the probability that <span class="math inline">\(Y\)</span> is some value other
than the baseline <span class="math inline">\(k\)</span> given <span class="math inline">\(X\)</span> and <span class="math inline">\(Pr(Y=K|X)\)</span> is the probability that <span class="math inline">\(Y\)</span> is the
baseline value <span class="math inline">\(K\)</span> given <span class="math inline">\(X\)</span>. In other works, the left-hand side is the _log odds of
<span class="math inline">\(k\)</span> versus <span class="math inline">\(K\)</span> given <span class="math inline">\(X\)</span>. This is an interesting point, but not entirely impactful, as
inferences or predictions based on this kind of model will be the same. Finally, this
expression can be extended to the case of multiple response and predictor variables like
so:</p>
<p><span class="math display">\[\ln{ \left( \frac{Pr(Y=k|X=x)}{Pr(Y=K|X=x)} \right) } = \beta_0 + \beta_1x_1 + \, ... \, + \beta_px_p\]</span></p>
<p>As an alternative to choosing a baseline category, the <em>softmax</em> coding of a logistic
regression model treats all <span class="math inline">\(K\)</span> classes symmetrically, such that the log odds ratio
between one categorical value <span class="math inline">\(k\)</span> and another <span class="math inline">\(k&#39;\)</span> can be represented as:</p>
<p><span class="math display">\[
ln{\left( \frac{Pr(Y=k|X=x}{Pr(Y=k&#39;|X=x)} \right) = (\beta_{k0} - \beta_{k&#39;0}) + (\beta_{k1} - \beta{k&#39;1})x_1 + \, ... \, + (\beta_{kp} - \beta_{k&#39;p})x_p}
\]</span></p>
<p>Similarly to the linear case, the fit to a logistic model can be fit by an equation.
Instead of the least squares method, logistic models are fit by a <em>maximum likelihood</em>
method. In the simple case with one predictor and a binary response variable, the
_maximum likelihood function_ attempts to estimate <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> in such a
way that the predicted probability <span class="math inline">\(\hat{p}(x_i)\)</span> matches the observed result as much as
possible. This means that, when <span class="math inline">\(Y\)</span> == <code>category</code> <span class="math inline">\(\hat{p}(x_i)\)</span> should be very close to
1 and when <span class="math inline">\(Y\)</span> != <code>category</code> <span class="math inline">\(\hat{p}(x_i)\)</span> should be very close to 0. This is
accomplished using a <em>likelihood function</em> of the form:</p>
<p><span class="math display">\[\ell(\beta_0, \beta_1) = \prod_{i:y_i = 1}{p(x_i)} \prod_{i&#39;:y_{i&#39;}=0}{(1 - p(x_{i&#39;}))}\]</span></p>
</div>
<div id="ch5-evaluating-validity" class="section level2 hasAnchor" number="5.3">
<h2><span class="header-section-number">5.3</span> Evaluating Validity<a href="chapter-5.html#ch5-evaluating-validity" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>As can be seen from the underlying math, there are several assumptions inherent in a
logistic regression model, regardless of the number of predictor variables or response
categories:</p>
<ul>
<li><p>Since the contribution by each set of predictors in each observation is calculated
independently for each response, it is assume that <em>each observation is
independent</em>.</p></li>
<li><p>Each predictor variable is assumed to be independent as well, that is, there is no
<a href="chapter-4.html#ch4-collinearity">collinearity</a> between predictors. This can be detected through
exploratory visualization using a scatterplot matrix, by calculating <em>variance
inflation factors</em> via <code>car::vif</code>, or by other methods.</p></li>
<li><p>Just as with linear regression models, the goodness-of-fit can be negatively
impacted by <a href="chapter-3.html#ch3-outliers">outliers</a> or <a href="chapter-3.html#ch3-high-leverage-points">high-leverage
points</a>.</p></li>
<li><p>Finally, as has been demonstrated, logistic regression assumes a linear relationship
between the log odds of the response belonging to a given category and the predictor
variables. This can be a bit more complicated to assess than in the linear case, but
a Box-Tidwell test (<code>car::boxTidwell</code>) or scatter plot can help. These methods are
demonstrated in the <a href="ch5-example">Example</a>.</p></li>
</ul>
</div>
<div id="ch5-evaluating-fit" class="section level2 hasAnchor" number="5.4">
<h2><span class="header-section-number">5.4</span> Evaluating Fit<a href="chapter-5.html#ch5-evaluating-fit" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="ch5-binomial-logistic-regression" class="section level3 hasAnchor" number="5.4.1">
<h3><span class="header-section-number">5.4.1</span> Binomial Logistic Regression<a href="chapter-5.html#ch5-binomial-logistic-regression" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>There are a variety of methods for evaluating the fit of a logistic regression. Unlike a
linear regression on a quantitative response, the ultimate output of a classification
model (such as a logistic regression) cannot be easily characterized by how <em>close</em> the
individual predicted response is to an observed response, in general, because the
response either <em>is</em> or <em>is not</em> classified correctly. Instead, population-wide measures
such as a <em>confusion matrix</em><a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a> can be used. Here’s what that looks like for a binomial
logistic regression on the <code>iris</code> data set, determining whether a particular flower is
of the <em>setosa</em> species.</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="chapter-5.html#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">6047</span>)</span>
<span id="cb48-2"><a href="chapter-5.html#cb48-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-3"><a href="chapter-5.html#cb48-3" aria-hidden="true" tabindex="-1"></a><span class="co"># I&#39;m going to start by switching around the classes on a few of the</span></span>
<span id="cb48-4"><a href="chapter-5.html#cb48-4" aria-hidden="true" tabindex="-1"></a><span class="co"># observations, just to make the confusion matrix more interesting. </span></span>
<span id="cb48-5"><a href="chapter-5.html#cb48-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Otherwise, our classifier will be _too_ good.</span></span>
<span id="cb48-6"><a href="chapter-5.html#cb48-6" aria-hidden="true" tabindex="-1"></a><span class="fu">skim</span>(</span>
<span id="cb48-7"><a href="chapter-5.html#cb48-7" aria-hidden="true" tabindex="-1"></a>  iris_data</span>
<span id="cb48-8"><a href="chapter-5.html#cb48-8" aria-hidden="true" tabindex="-1"></a>  <span class="ot">&lt;-</span> iris</span>
<span id="cb48-9"><a href="chapter-5.html#cb48-9" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">mutate</span>(</span>
<span id="cb48-10"><a href="chapter-5.html#cb48-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">replace =</span> <span class="fu">sample</span>(Species, <span class="fu">n</span>()),</span>
<span id="cb48-11"><a href="chapter-5.html#cb48-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">Species =</span> <span class="fu">if_else</span>(<span class="fu">runif</span>(<span class="fu">n</span>(), <span class="dv">0</span>, <span class="dv">1</span>) <span class="sc">&gt;</span> .<span class="dv">15</span>, Species, replace),</span>
<span id="cb48-12"><a href="chapter-5.html#cb48-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">setosa  =</span> <span class="fu">factor</span>(Species <span class="sc">==</span> <span class="st">&quot;setosa&quot;</span>, <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">&quot;TRUE&quot;</span>, <span class="st">&quot;FALSE&quot;</span>)),</span>
<span id="cb48-13"><a href="chapter-5.html#cb48-13" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb48-14"><a href="chapter-5.html#cb48-14" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">select</span>(Species, setosa, <span class="fu">matches</span>(<span class="st">&quot;(Length|Width)$&quot;</span>))</span>
<span id="cb48-15"><a href="chapter-5.html#cb48-15" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<table>
<caption><span id="tab:ch5-2">Table 5.2: </span>Data summary</caption>
<tbody>
<tr class="odd">
<td align="left">Name</td>
<td align="left">… &lt;- NULL</td>
</tr>
<tr class="even">
<td align="left">Number of rows</td>
<td align="left">150</td>
</tr>
<tr class="odd">
<td align="left">Number of columns</td>
<td align="left">6</td>
</tr>
<tr class="even">
<td align="left">_______________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Column type frequency:</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">factor</td>
<td align="left">2</td>
</tr>
<tr class="odd">
<td align="left">numeric</td>
<td align="left">4</td>
</tr>
<tr class="even">
<td align="left">________________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Group variables</td>
<td align="left">None</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: factor</strong></p>
<table style="width:100%;">
<colgroup>
<col width="17%" />
<col width="12%" />
<col width="17%" />
<col width="9%" />
<col width="11%" />
<col width="32%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="left">ordered</th>
<th align="right">n_unique</th>
<th align="left">top_counts</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Species</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">FALSE</td>
<td align="right">3</td>
<td align="left">ver: 52, vir: 50, set: 48</td>
</tr>
<tr class="even">
<td align="left">setosa</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">FALSE</td>
<td align="right">2</td>
<td align="left">FAL: 102, TRU: 48</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table style="width:100%;">
<colgroup>
<col width="18%" />
<col width="13%" />
<col width="18%" />
<col width="6%" />
<col width="6%" />
<col width="5%" />
<col width="5%" />
<col width="6%" />
<col width="5%" />
<col width="6%" />
<col width="7%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="right">p0</th>
<th align="right">p25</th>
<th align="right">p50</th>
<th align="right">p75</th>
<th align="right">p100</th>
<th align="left">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Sepal.Length</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">5.84</td>
<td align="right">0.83</td>
<td align="right">4.3</td>
<td align="right">5.1</td>
<td align="right">5.80</td>
<td align="right">6.4</td>
<td align="right">7.9</td>
<td align="left">▆▇▇▅▂</td>
</tr>
<tr class="even">
<td align="left">Sepal.Width</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">3.06</td>
<td align="right">0.44</td>
<td align="right">2.0</td>
<td align="right">2.8</td>
<td align="right">3.00</td>
<td align="right">3.3</td>
<td align="right">4.4</td>
<td align="left">▁▆▇▂▁</td>
</tr>
<tr class="odd">
<td align="left">Petal.Length</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">3.76</td>
<td align="right">1.77</td>
<td align="right">1.0</td>
<td align="right">1.6</td>
<td align="right">4.35</td>
<td align="right">5.1</td>
<td align="right">6.9</td>
<td align="left">▇▁▆▇▂</td>
</tr>
<tr class="even">
<td align="left">Petal.Width</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1.20</td>
<td align="right">0.76</td>
<td align="right">0.1</td>
<td align="right">0.3</td>
<td align="right">1.30</td>
<td align="right">1.8</td>
<td align="right">2.5</td>
<td align="left">▇▁▇▅▃</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="chapter-5.html#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co"># This recipe assumes that `Species` is predicted by all other values,</span></span>
<span id="cb49-2"><a href="chapter-5.html#cb49-2" aria-hidden="true" tabindex="-1"></a><span class="co"># creates interaction terms, and normalizes all the numeric predictors.</span></span>
<span id="cb49-3"><a href="chapter-5.html#cb49-3" aria-hidden="true" tabindex="-1"></a>(iris_recipe</span>
<span id="cb49-4"><a href="chapter-5.html#cb49-4" aria-hidden="true" tabindex="-1"></a>  <span class="ot">&lt;-</span> <span class="fu">recipe</span>(setosa <span class="sc">~</span> ., <span class="at">data =</span> iris_data)</span>
<span id="cb49-5"><a href="chapter-5.html#cb49-5" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">step_rm</span>(Species) <span class="co"># no cheating!</span></span>
<span id="cb49-6"><a href="chapter-5.html#cb49-6" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">step_interact</span>(setosa <span class="sc">~</span> Sepal.Length<span class="sc">:</span>Sepal.Width)</span>
<span id="cb49-7"><a href="chapter-5.html#cb49-7" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">step_interact</span>(setosa <span class="sc">~</span> Petal.Length<span class="sc">:</span>Petal.Width)</span>
<span id="cb49-8"><a href="chapter-5.html#cb49-8" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">step_normalize</span>(<span class="fu">all_numeric_predictors</span>()))</span></code></pre></div>
<pre><code>## Recipe
## 
## Inputs:
## 
##       role #variables
##    outcome          1
##  predictor          5
## 
## Operations:
## 
## Variables removed Species
## Interactions with setosa, Sepal.Length:Sepal.Width
## Interactions with setosa, Petal.Length:Petal.Width
## Centering and scaling for all_numeric_predictors()</code></pre>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="chapter-5.html#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Specify the model</span></span>
<span id="cb51-2"><a href="chapter-5.html#cb51-2" aria-hidden="true" tabindex="-1"></a>(iris_model</span>
<span id="cb51-3"><a href="chapter-5.html#cb51-3" aria-hidden="true" tabindex="-1"></a>  <span class="ot">&lt;-</span> <span class="fu">logistic_reg</span>()</span>
<span id="cb51-4"><a href="chapter-5.html#cb51-4" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">set_engine</span>(<span class="st">&quot;glm&quot;</span>)</span>
<span id="cb51-5"><a href="chapter-5.html#cb51-5" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">set_mode</span>(<span class="st">&quot;classification&quot;</span>))</span></code></pre></div>
<pre><code>## Logistic Regression Model Specification (classification)
## 
## Computational engine: glm</code></pre>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="chapter-5.html#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Bundle into a workflow (with fit)</span></span>
<span id="cb53-2"><a href="chapter-5.html#cb53-2" aria-hidden="true" tabindex="-1"></a>(iris_workflow</span>
<span id="cb53-3"><a href="chapter-5.html#cb53-3" aria-hidden="true" tabindex="-1"></a>  <span class="ot">&lt;-</span> <span class="fu">workflow</span>()</span>
<span id="cb53-4"><a href="chapter-5.html#cb53-4" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">add_recipe</span>(iris_recipe)</span>
<span id="cb53-5"><a href="chapter-5.html#cb53-5" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">add_model</span>(iris_model)</span>
<span id="cb53-6"><a href="chapter-5.html#cb53-6" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">fit</span>(<span class="at">data =</span> iris_data))</span></code></pre></div>
<pre><code>## ══ Workflow [trained] ═══════════════════════════════════════════════════════════════════════════════
## Preprocessor: Recipe
## Model: logistic_reg()
## 
## ── Preprocessor ─────────────────────────────────────────────────────────────────────────────────────
## 4 Recipe Steps
## 
## • step_rm()
## • step_interact()
## • step_interact()
## • step_normalize()
## 
## ── Model ────────────────────────────────────────────────────────────────────────────────────────────
## 
## Call:  stats::glm(formula = ..y ~ ., family = stats::binomial, data = data)
## 
## Coefficients:
##                (Intercept)                Sepal.Length                 Sepal.Width  
##                     1.9093                      1.8128                     -0.5969  
##               Petal.Length                 Petal.Width  Sepal.Length_x_Sepal.Width  
##                     2.4619                      7.7695                     -0.2847  
## Petal.Length_x_Petal.Width  
##                    -9.3748  
## 
## Degrees of Freedom: 149 Total (i.e. Null);  143 Residual
## Null Deviance:       188.1 
## Residual Deviance: 51.93     AIC: 65.93</code></pre>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="chapter-5.html#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Add predictions to the input data</span></span>
<span id="cb55-2"><a href="chapter-5.html#cb55-2" aria-hidden="true" tabindex="-1"></a>iris_predictions <span class="ot">&lt;-</span> <span class="fu">augment</span>(iris_workflow, iris_data)</span>
<span id="cb55-3"><a href="chapter-5.html#cb55-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-4"><a href="chapter-5.html#cb55-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a confusion matrix (table)</span></span>
<span id="cb55-5"><a href="chapter-5.html#cb55-5" aria-hidden="true" tabindex="-1"></a>(confusion_matrix</span>
<span id="cb55-6"><a href="chapter-5.html#cb55-6" aria-hidden="true" tabindex="-1"></a>  <span class="ot">&lt;-</span> iris_predictions</span>
<span id="cb55-7"><a href="chapter-5.html#cb55-7" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">count</span>(setosa, .pred_class)</span>
<span id="cb55-8"><a href="chapter-5.html#cb55-8" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">pivot_wider</span>(<span class="at">names_from =</span> .pred_class, <span class="at">values_from =</span> n))</span></code></pre></div>
<pre><code>## # A tibble: 2 × 3
##   setosa `TRUE` `FALSE`
##   &lt;fct&gt;   &lt;int&gt;   &lt;int&gt;
## 1 TRUE       45       3
## 2 FALSE       5      97</code></pre>
<p>In this binary case, the results can be classified in four different ways:</p>
<ul>
<li><p>A <em>true positive</em> [<span class="math inline">\(TP\)</span>] is a case where the observed value is ‘true’ and the
predicted value is ‘true’.</p></li>
<li><p>A <em>true negative</em> [<span class="math inline">\(TN\)</span>] is a case where the observed value is ‘false’ and the
predicted value is ‘false’.</p></li>
<li><p>A <em>false positive</em> [<span class="math inline">\(FP\)</span>] is a case where the observed value is ‘false’ and the
predicted value is ‘true’.</p></li>
<li><p>A <em>false negative</em> [<span class="math inline">\(FN\)</span>] is a case where the observed value is ‘true’ and the
predicted value is ‘false’.</p></li>
</ul>
<p>The counts of observations in these four ‘buckets’ can be used to calculate a variety of
useful measures:</p>
<ul>
<li><p><em>Precision</em> [<span class="math inline">\(TP/(TP + FP)\)</span>] is defined as the proportion of predicted positives
that are actually positive. Also called <em>positive predictive value</em>. Answers the
question: “Of all the flowers the model predicted to be <em>setosa</em>, what fraction
actually were?”</p></li>
<li><p><em>Recall</em> [<span class="math inline">\(TP/(TP + FN)\)</span>] is defined as the proportion of positive results out of
the number of samples which were actually positive. Also called <em>sensitivity</em>.
Answers the question: “Of all the flowers that are actually <em>setosa</em>, what fraction
did the model identify?”</p></li>
<li><p><em>Specificity</em> [<span class="math inline">\(TN/(TN + FP)\)</span>] is defined as the proportion of negative results out
of the number of samples which were actually negative. Answers the question: “Of all
flowers that were <strong>not</strong> <em>setosa</em>, what fraction did the model identify?”</p></li>
<li><p><em>Accuracy</em> [<span class="math inline">\((TP + TN)/(TP + TN + FP + FN)\)</span>] is the percentage of labels predicted
accurately for a sample. Answers the question: “Of all the observations, what
fraction were correctly classified?”</p></li>
<li><p><em>F Measure</em> is a weighted average of the precision and recall, with best 1 and worst
being 0.</p></li>
<li><p><em>Cohen’s Kappa</em> is also used to evaluate inter-rater reliability, but if one
considers the observed classification to be set by one <em>rater</em> and the predicted
classes to be set by another <em>rater</em>, it can be usefully applied to classification
models. When applied in this way, <span class="math inline">\(\kappa\)</span> provides an estimate of how much better
the observed accuracy (calculated as shown above) is than the expected accuracy
(shown below). For example, if the expected accuracy is 50% (random chance) and the
observed accuracy is 95%, <span class="math inline">\(\kappa\)</span> will be 0.90. This is especially useful when the
class distribution is skewed. <span class="math inline">\(\kappa\)</span> can be calculated as shown:</p>
<p><span class="math display">\[\begin{align}
observations &amp;= n = TP + TN + FP + FN \\
accuracy_{obs} &amp;= \frac{TP + TN}{n}\\
accuracy_{exp} &amp;= \left(\frac{TP * FP}{obs} + \frac{TN * FN}{obs}\right) \div n\\
\kappa &amp;= \frac{accuracy_{obs} - accuracy{exp}}{1 - accuracy_{exp}}
\end{align}\]</span></p></li>
</ul>
<p>As described in <a href="chapter-5.html#ch5-how-it-works">How it Works</a>, a logistic regression model doesn’t
<em>exactly</em> predict the class of each observation, but a set of probabilities that the
observation belongs to each class. In the binary case, these are the probability that
the observed class is ‘true’ ($p(X)$) and the probability that it is ‘false’ ($1 -
p(X)$). By default, if <span class="math inline">\(p(X) &gt; 0.5\)</span>, then the predicted class will be ‘true’. This
threshold can be manipulated in order to further evaluate the model fit. By plotting the
<em>sensitivity</em> against [1 - <em>specificity</em>] for a range of threshold values, you get a
<em>received operator characteristic</em> (ROC) chart:</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb57-1"><a href="chapter-5.html#cb57-1" aria-hidden="true" tabindex="-1"></a>(iris_predictions</span>
<span id="cb57-2"><a href="chapter-5.html#cb57-2" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">roc_curve</span>(<span class="at">truth =</span> setosa, .pred_TRUE) </span>
<span id="cb57-3"><a href="chapter-5.html#cb57-3" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">autoplot</span>())</span></code></pre></div>
<p><img src="_main_files/figure-html/ch5-3-1.png" width="672" /></p>
<p>The dotted diagonal line represents the probability of randomly guessing the correct
class, so you want to be as far from that line as possible! For a theoretical model
making perfect predictions, the curve would rise straight up the left side then across
the top. The <em>area under the curve</em> (AUC) is a value between 0 and 1 that provides a
quantitative measurement of the performance indicated by the ROC curve. The closer this
value is to 1, the better the model has performed.</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="chapter-5.html#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a set of metrics using the `yardstick` package</span></span>
<span id="cb58-2"><a href="chapter-5.html#cb58-2" aria-hidden="true" tabindex="-1"></a>eval_metrics <span class="ot">&lt;-</span> <span class="fu">metric_set</span>(ppv,    recall, specificity, accuracy, </span>
<span id="cb58-3"><a href="chapter-5.html#cb58-3" aria-hidden="true" tabindex="-1"></a>                           f_meas, kap,    roc_auc)</span>
<span id="cb58-4"><a href="chapter-5.html#cb58-4" aria-hidden="true" tabindex="-1"></a><span class="fu">eval_metrics</span>(</span>
<span id="cb58-5"><a href="chapter-5.html#cb58-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> iris_predictions, </span>
<span id="cb58-6"><a href="chapter-5.html#cb58-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">truth =</span> setosa, </span>
<span id="cb58-7"><a href="chapter-5.html#cb58-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">estimate =</span> .pred_class,</span>
<span id="cb58-8"><a href="chapter-5.html#cb58-8" aria-hidden="true" tabindex="-1"></a>  .pred_TRUE  <span class="co"># to be passed to `roc_auc()`</span></span>
<span id="cb58-9"><a href="chapter-5.html#cb58-9" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## # A tibble: 7 × 3
##   .metric     .estimator .estimate
##   &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;
## 1 ppv         binary         0.9  
## 2 recall      binary         0.938
## 3 specificity binary         0.951
## 4 accuracy    binary         0.947
## 5 f_meas      binary         0.918
## 6 kap         binary         0.879
## 7 roc_auc     binary         0.978</code></pre>
</div>
<div id="ch5-multinomial-logistic-regression" class="section level3 hasAnchor" number="5.4.2">
<h3><span class="header-section-number">5.4.2</span> Multinomial Logistic Regression<a href="chapter-5.html#ch5-multinomial-logistic-regression" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>When expanding our predictive value to predicting <em>all</em> classes of iris species:</p>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="chapter-5.html#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="co"># This recipe assumes that `Species` is predicted by all other values,</span></span>
<span id="cb60-2"><a href="chapter-5.html#cb60-2" aria-hidden="true" tabindex="-1"></a><span class="co"># creates interaction terms, and normalizes all the numeric predictors.</span></span>
<span id="cb60-3"><a href="chapter-5.html#cb60-3" aria-hidden="true" tabindex="-1"></a>(iris_recipe</span>
<span id="cb60-4"><a href="chapter-5.html#cb60-4" aria-hidden="true" tabindex="-1"></a>  <span class="ot">&lt;-</span> <span class="fu">recipe</span>(Species <span class="sc">~</span> ., <span class="at">data =</span> iris_data)</span>
<span id="cb60-5"><a href="chapter-5.html#cb60-5" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">step_rm</span>(setosa) <span class="co"># No cheating!</span></span>
<span id="cb60-6"><a href="chapter-5.html#cb60-6" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">step_interact</span>(Species <span class="sc">~</span> Sepal.Length<span class="sc">:</span>Sepal.Width)</span>
<span id="cb60-7"><a href="chapter-5.html#cb60-7" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">step_interact</span>(Species <span class="sc">~</span> Petal.Length<span class="sc">:</span>Petal.Width)</span>
<span id="cb60-8"><a href="chapter-5.html#cb60-8" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">step_normalize</span>(<span class="fu">all_numeric_predictors</span>()))</span></code></pre></div>
<pre><code>## Recipe
## 
## Inputs:
## 
##       role #variables
##    outcome          1
##  predictor          5
## 
## Operations:
## 
## Variables removed setosa
## Interactions with Species, Sepal.Length:Sepal.Width
## Interactions with Species, Petal.Length:Petal.Width
## Centering and scaling for all_numeric_predictors()</code></pre>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="chapter-5.html#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Specify the model</span></span>
<span id="cb62-2"><a href="chapter-5.html#cb62-2" aria-hidden="true" tabindex="-1"></a>(iris_model</span>
<span id="cb62-3"><a href="chapter-5.html#cb62-3" aria-hidden="true" tabindex="-1"></a>  <span class="ot">&lt;-</span> <span class="fu">multinom_reg</span>()      <span class="co"># Since there are three possible classes</span></span>
<span id="cb62-4"><a href="chapter-5.html#cb62-4" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">set_engine</span>(<span class="st">&quot;nnet&quot;</span>)  <span class="co"># Default for `multinom_reg`</span></span>
<span id="cb62-5"><a href="chapter-5.html#cb62-5" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">set_mode</span>(<span class="st">&quot;classification&quot;</span>))</span></code></pre></div>
<pre><code>## Multinomial Regression Model Specification (classification)
## 
## Computational engine: nnet</code></pre>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="chapter-5.html#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Bundle into a workflow (with fit)</span></span>
<span id="cb64-2"><a href="chapter-5.html#cb64-2" aria-hidden="true" tabindex="-1"></a>(iris_workflow</span>
<span id="cb64-3"><a href="chapter-5.html#cb64-3" aria-hidden="true" tabindex="-1"></a>  <span class="ot">&lt;-</span> <span class="fu">workflow</span>()</span>
<span id="cb64-4"><a href="chapter-5.html#cb64-4" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">add_recipe</span>(iris_recipe)</span>
<span id="cb64-5"><a href="chapter-5.html#cb64-5" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">add_model</span>(iris_model)</span>
<span id="cb64-6"><a href="chapter-5.html#cb64-6" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">fit</span>(<span class="at">data =</span> iris_data))</span></code></pre></div>
<pre><code>## ══ Workflow [trained] ═══════════════════════════════════════════════════════════════════════════════
## Preprocessor: Recipe
## Model: multinom_reg()
## 
## ── Preprocessor ─────────────────────────────────────────────────────────────────────────────────────
## 4 Recipe Steps
## 
## • step_rm()
## • step_interact()
## • step_interact()
## • step_normalize()
## 
## ── Model ────────────────────────────────────────────────────────────────────────────────────────────
## Call:
## nnet::multinom(formula = ..y ~ ., data = data, trace = FALSE)
## 
## Coefficients:
##            (Intercept) Sepal.Length Sepal.Width Petal.Length Petal.Width Sepal.Length_x_Sepal.Width
## versicolor   0.3185672    -1.562520  -4.3193520     5.836776   14.121343                   5.036399
## virginica    0.9500096     1.757604  -0.1347156     2.114512    4.658676                  -1.056959
##            Petal.Length_x_Petal.Width
## versicolor                 -20.916383
## virginica                   -5.287086
## 
## Residual Deviance: 111.6001 
## AIC: 139.6001</code></pre>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb66-1"><a href="chapter-5.html#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Add predictions to the input data</span></span>
<span id="cb66-2"><a href="chapter-5.html#cb66-2" aria-hidden="true" tabindex="-1"></a>iris_predictions <span class="ot">&lt;-</span> <span class="fu">augment</span>(iris_workflow, iris_data)</span>
<span id="cb66-3"><a href="chapter-5.html#cb66-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-4"><a href="chapter-5.html#cb66-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a confusion matrix (table)</span></span>
<span id="cb66-5"><a href="chapter-5.html#cb66-5" aria-hidden="true" tabindex="-1"></a>(confusion_matrix</span>
<span id="cb66-6"><a href="chapter-5.html#cb66-6" aria-hidden="true" tabindex="-1"></a>  <span class="ot">&lt;-</span> iris_predictions</span>
<span id="cb66-7"><a href="chapter-5.html#cb66-7" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">count</span>(Species, .pred_class)</span>
<span id="cb66-8"><a href="chapter-5.html#cb66-8" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">pivot_wider</span>(<span class="at">names_from =</span> .pred_class, <span class="at">values_from =</span> n))</span></code></pre></div>
<pre><code>## # A tibble: 3 × 4
##   Species    setosa versicolor virginica
##   &lt;fct&gt;       &lt;int&gt;      &lt;int&gt;     &lt;int&gt;
## 1 setosa         43          3         2
## 2 versicolor      3         45         4
## 3 virginica       2          4        44</code></pre>
<p>Here we see that our relatively “un-tuned” model does a good job of identifying iris
species with just a few mis-classifications (due in large part to our ‘tweaks’ to the
data set). Each row represents the true class of the flower while each column represents
the predicted class of each flower. In a perfect world, we would only have numbers on
the diagonal. We can examine the same metrics as we did in the binomial case:</p>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb68-1"><a href="chapter-5.html#cb68-1" aria-hidden="true" tabindex="-1"></a>eval_metrics <span class="ot">&lt;-</span> <span class="fu">metric_set</span>(ppv,    recall, specificity, accuracy, </span>
<span id="cb68-2"><a href="chapter-5.html#cb68-2" aria-hidden="true" tabindex="-1"></a>                           f_meas, kap,    roc_auc)</span>
<span id="cb68-3"><a href="chapter-5.html#cb68-3" aria-hidden="true" tabindex="-1"></a><span class="fu">eval_metrics</span>(</span>
<span id="cb68-4"><a href="chapter-5.html#cb68-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> iris_predictions, </span>
<span id="cb68-5"><a href="chapter-5.html#cb68-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">truth =</span> Species, </span>
<span id="cb68-6"><a href="chapter-5.html#cb68-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">estimate =</span> .pred_class, </span>
<span id="cb68-7"><a href="chapter-5.html#cb68-7" aria-hidden="true" tabindex="-1"></a>  .pred_setosa,      <span class="co"># to be passed to `roc_auc()`</span></span>
<span id="cb68-8"><a href="chapter-5.html#cb68-8" aria-hidden="true" tabindex="-1"></a>  .pred_versicolor,  <span class="co"># / /</span></span>
<span id="cb68-9"><a href="chapter-5.html#cb68-9" aria-hidden="true" tabindex="-1"></a>  .pred_virginica    <span class="co"># /</span></span>
<span id="cb68-10"><a href="chapter-5.html#cb68-10" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## # A tibble: 7 × 3
##   .metric     .estimator .estimate
##   &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;
## 1 ppv         macro          0.880
## 2 recall      macro          0.880
## 3 specificity macro          0.940
## 4 accuracy    multiclass     0.88 
## 5 f_meas      macro          0.880
## 6 kap         multiclass     0.820
## 7 roc_auc     hand_till      0.956</code></pre>
</div>
</div>
<div id="ch5-example" class="section level2 hasAnchor" number="5.5">
<h2><span class="header-section-number">5.5</span> Example<a href="chapter-5.html#ch5-example" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="dataset" class="section level3 hasAnchor" number="5.5.1">
<h3><span class="header-section-number">5.5.1</span> Dataset<a href="chapter-5.html#dataset" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>For our example logistic regression, let’s attempt to classify diamonds by expected
‘price class’ using the <code>diamonds</code> dataset.</p>
<div class="sourceCode r" style="padding:1em;box-shadow: 10px 5px 5px #f7f7f7;">
<!DOCTYPE html><html><head><title>R: Prices of over 50,000 round cut diamonds</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.css">
<script type="text/javascript">
const macros = { "\\R": "\\textsf{R}", "\\code": "\\texttt"};
function processMathHTML() {
    var l = document.getElementsByClassName('reqn');
    for (let e of l) { katex.render(e.textContent, e, { throwOnError: false, macros }); }
    return;
}</script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.15.3/dist/katex.min.js"
    onload="processMathHTML();"></script>
<link rel="stylesheet" type="text/css" href="R.css" />
</head><body><div class="container">

<table style="width: 100%;"><tr><td>diamonds</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2>Prices of over 50,000 round cut diamonds</h2>

<h3>Description</h3>

<p>A dataset containing the prices and other attributes of almost 54,000
diamonds. The variables are as follows:
</p>


<h3>Usage</h3>

<pre><code class='language-R'>diamonds
</code></pre>


<h3>Format</h3>

<p>A data frame with 53940 rows and 10 variables:
</p>

<dl>
<dt>price</dt><dd><p>price in US dollars (\$326&ndash;\$18,823)</p>
</dd>
<dt>carat</dt><dd><p>weight of the diamond (0.2&ndash;5.01)</p>
</dd>
<dt>cut</dt><dd><p>quality of the cut (Fair, Good, Very Good, Premium, Ideal)</p>
</dd>
<dt>color</dt><dd><p>diamond colour, from D (best) to J (worst)</p>
</dd>
<dt>clarity</dt><dd><p>a measurement of how clear the diamond is (I1 (worst), SI2,
SI1, VS2, VS1, VVS2, VVS1, IF (best))</p>
</dd>
<dt>x</dt><dd><p>length in mm (0&ndash;10.74)</p>
</dd>
<dt>y</dt><dd><p>width in mm (0&ndash;58.9)</p>
</dd>
<dt>z</dt><dd><p>depth in mm (0&ndash;31.8)</p>
</dd>
<dt>depth</dt><dd><p>total depth percentage = z / mean(x, y) = 2 * z / (x + y) (43&ndash;79)</p>
</dd>
<dt>table</dt><dd><p>width of top of diamond relative to widest point (43&ndash;95)</p>
</dd>
</dl>



</div>
</body></html>
</div>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb70-1"><a href="chapter-5.html#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="fu">skim</span>(diamonds)</span></code></pre></div>
<table>
<caption><span id="tab:ch5-8">Table 5.3: </span>Data summary</caption>
<tbody>
<tr class="odd">
<td align="left">Name</td>
<td align="left">diamonds</td>
</tr>
<tr class="even">
<td align="left">Number of rows</td>
<td align="left">53940</td>
</tr>
<tr class="odd">
<td align="left">Number of columns</td>
<td align="left">10</td>
</tr>
<tr class="even">
<td align="left">_______________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Column type frequency:</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">factor</td>
<td align="left">3</td>
</tr>
<tr class="odd">
<td align="left">numeric</td>
<td align="left">7</td>
</tr>
<tr class="even">
<td align="left">________________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Group variables</td>
<td align="left">None</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: factor</strong></p>
<table>
<colgroup>
<col width="13%" />
<col width="9%" />
<col width="13%" />
<col width="7%" />
<col width="8%" />
<col width="45%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="left">ordered</th>
<th align="right">n_unique</th>
<th align="left">top_counts</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">cut</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">TRUE</td>
<td align="right">5</td>
<td align="left">Ide: 21551, Pre: 13791, Ver: 12082, Goo: 4906</td>
</tr>
<tr class="even">
<td align="left">color</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">TRUE</td>
<td align="right">7</td>
<td align="left">G: 11292, E: 9797, F: 9542, H: 8304</td>
</tr>
<tr class="odd">
<td align="left">clarity</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">TRUE</td>
<td align="right">8</td>
<td align="left">SI1: 13065, VS2: 12258, SI2: 9194, VS1: 8171</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table style="width:100%;">
<colgroup>
<col width="14%" />
<col width="10%" />
<col width="14%" />
<col width="8%" />
<col width="8%" />
<col width="6%" />
<col width="7%" />
<col width="8%" />
<col width="8%" />
<col width="9%" />
<col width="6%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="right">p0</th>
<th align="right">p25</th>
<th align="right">p50</th>
<th align="right">p75</th>
<th align="right">p100</th>
<th align="left">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">carat</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">0.80</td>
<td align="right">0.47</td>
<td align="right">0.2</td>
<td align="right">0.40</td>
<td align="right">0.70</td>
<td align="right">1.04</td>
<td align="right">5.01</td>
<td align="left">▇▂▁▁▁</td>
</tr>
<tr class="even">
<td align="left">depth</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">61.75</td>
<td align="right">1.43</td>
<td align="right">43.0</td>
<td align="right">61.00</td>
<td align="right">61.80</td>
<td align="right">62.50</td>
<td align="right">79.00</td>
<td align="left">▁▁▇▁▁</td>
</tr>
<tr class="odd">
<td align="left">table</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">57.46</td>
<td align="right">2.23</td>
<td align="right">43.0</td>
<td align="right">56.00</td>
<td align="right">57.00</td>
<td align="right">59.00</td>
<td align="right">95.00</td>
<td align="left">▁▇▁▁▁</td>
</tr>
<tr class="even">
<td align="left">price</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">3932.80</td>
<td align="right">3989.44</td>
<td align="right">326.0</td>
<td align="right">950.00</td>
<td align="right">2401.00</td>
<td align="right">5324.25</td>
<td align="right">18823.00</td>
<td align="left">▇▂▁▁▁</td>
</tr>
<tr class="odd">
<td align="left">x</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">5.73</td>
<td align="right">1.12</td>
<td align="right">0.0</td>
<td align="right">4.71</td>
<td align="right">5.70</td>
<td align="right">6.54</td>
<td align="right">10.74</td>
<td align="left">▁▁▇▃▁</td>
</tr>
<tr class="even">
<td align="left">y</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">5.73</td>
<td align="right">1.14</td>
<td align="right">0.0</td>
<td align="right">4.72</td>
<td align="right">5.71</td>
<td align="right">6.54</td>
<td align="right">58.90</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="odd">
<td align="left">z</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">3.54</td>
<td align="right">0.71</td>
<td align="right">0.0</td>
<td align="right">2.91</td>
<td align="right">3.53</td>
<td align="right">4.04</td>
<td align="right">31.80</td>
<td align="left">▇▁▁▁▁</td>
</tr>
</tbody>
</table>
</div>
<div id="response-categories" class="section level3 hasAnchor" number="5.5.2">
<h3><span class="header-section-number">5.5.2</span> Response Categories<a href="chapter-5.html#response-categories" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Because I know I want to predict a ‘price class’ as a category instead of as continuous
value, I should try to determine how large the range of prices in each category should
be. Ideally, each price category should contain a comparable number of observations.
You’d also want to consider the business use case here, but since this is an example of
logistic regression modeling more than a primer on the diamond trade, let’s stick to
making roughly equal size groups. Let’s take a look a the distribution of <code>price</code>.</p>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="chapter-5.html#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(diamonds, <span class="fu">aes</span>(price)) <span class="sc">+</span></span>
<span id="cb71-2"><a href="chapter-5.html#cb71-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">bins =</span> <span class="dv">50</span>) <span class="sc">+</span></span>
<span id="cb71-3"><a href="chapter-5.html#cb71-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code></pre></div>
<p><img src="_main_files/figure-html/ch5-9-1.png" width="672" /></p>
<p>Oh, well, that’s troublesome. Looks like we’ll need to log-transform <code>price</code> if we want
it to be evenly distributed across the range.</p>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="chapter-5.html#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(diamonds, <span class="fu">aes</span>(<span class="fu">log</span>(price))) <span class="sc">+</span></span>
<span id="cb72-2"><a href="chapter-5.html#cb72-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">bins =</span> <span class="dv">50</span>) <span class="sc">+</span></span>
<span id="cb72-3"><a href="chapter-5.html#cb72-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code></pre></div>
<p><img src="_main_files/figure-html/ch5-10-1.png" width="672" /></p>
<p>That’s <em>much</em> better. Now, let’s identify the optimal interval size:</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="chapter-5.html#cb73-1" aria-hidden="true" tabindex="-1"></a>(<span class="fu">tibble</span>(<span class="at">buckets =</span> <span class="fu">seq_len</span>(<span class="dv">10</span>))</span>
<span id="cb73-2"><a href="chapter-5.html#cb73-2" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">mutate</span>(<span class="at">.calc =</span> <span class="fu">map</span>(buckets, <span class="sc">~</span> (</span>
<span id="cb73-3"><a href="chapter-5.html#cb73-3" aria-hidden="true" tabindex="-1"></a>    diamonds</span>
<span id="cb73-4"><a href="chapter-5.html#cb73-4" aria-hidden="true" tabindex="-1"></a>    <span class="sc">|&gt;</span> <span class="fu">mutate</span>(<span class="at">bucket =</span> <span class="fu">cut_interval</span>(<span class="fu">log</span>(price), .x))</span>
<span id="cb73-5"><a href="chapter-5.html#cb73-5" aria-hidden="true" tabindex="-1"></a>    <span class="sc">|&gt;</span> <span class="fu">count</span>(bucket)</span>
<span id="cb73-6"><a href="chapter-5.html#cb73-6" aria-hidden="true" tabindex="-1"></a>    <span class="sc">|&gt;</span> <span class="fu">summarise</span>(</span>
<span id="cb73-7"><a href="chapter-5.html#cb73-7" aria-hidden="true" tabindex="-1"></a>      <span class="at">mean_obs =</span> <span class="fu">mean</span>(n), </span>
<span id="cb73-8"><a href="chapter-5.html#cb73-8" aria-hidden="true" tabindex="-1"></a>      <span class="at">sd_obs   =</span> <span class="fu">sd</span>(n),</span>
<span id="cb73-9"><a href="chapter-5.html#cb73-9" aria-hidden="true" tabindex="-1"></a>      <span class="at">min_obs  =</span> <span class="fu">min</span>(n),</span>
<span id="cb73-10"><a href="chapter-5.html#cb73-10" aria-hidden="true" tabindex="-1"></a>      <span class="at">max_obs  =</span> <span class="fu">max</span>(n),</span>
<span id="cb73-11"><a href="chapter-5.html#cb73-11" aria-hidden="true" tabindex="-1"></a>      <span class="at">range    =</span> max_obs <span class="sc">-</span> min_obs,</span>
<span id="cb73-12"><a href="chapter-5.html#cb73-12" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb73-13"><a href="chapter-5.html#cb73-13" aria-hidden="true" tabindex="-1"></a>  )))</span>
<span id="cb73-14"><a href="chapter-5.html#cb73-14" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">unnest</span>(.calc))</span></code></pre></div>
<pre><code>## # A tibble: 10 × 6
##    buckets mean_obs sd_obs min_obs max_obs range
##      &lt;int&gt;    &lt;dbl&gt;  &lt;dbl&gt;   &lt;int&gt;   &lt;int&gt; &lt;int&gt;
##  1       1   53940     NA    53940   53940     0
##  2       2   26970    617.   26534   27406   872
##  3       3   17980   2635.   15241   20498  5257
##  4       4   13485   3230.    9581   16953  7372
##  5       5   10788   2991.    7144   13443  6299
##  6       6    8990   3078.    5200   13001  7801
##  7       7    7706.  2854.    3665   11568  7903
##  8       8    6742.  2491.    2618    9681  7063
##  9       9    5993.  2195.    1997    8258  6261
## 10      10    5394   2106.    1553    8400  6847</code></pre>
<p>It looks like 5 groups provides a good balance between the class sizes and the number of
classes.</p>
</div>
<div id="correlations" class="section level3 hasAnchor" number="5.5.3">
<h3><span class="header-section-number">5.5.3</span> Correlations<a href="chapter-5.html#correlations" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let’s start by establishing the correlations amongst the numeric variables in this
dataset:</p>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="chapter-5.html#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Use a scatterplot matrix to identify correlations</span></span>
<span id="cb75-2"><a href="chapter-5.html#cb75-2" aria-hidden="true" tabindex="-1"></a>columns <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;price&quot;</span>, <span class="st">&quot;carat&quot;</span>, <span class="st">&quot;depth&quot;</span>, <span class="st">&quot;table&quot;</span>, <span class="st">&quot;x&quot;</span>, <span class="st">&quot;y&quot;</span>, <span class="st">&quot;z&quot;</span>)</span>
<span id="cb75-3"><a href="chapter-5.html#cb75-3" aria-hidden="true" tabindex="-1"></a>GGally<span class="sc">::</span><span class="fu">ggpairs</span>(diamonds, <span class="at">columns =</span> columns, <span class="at">progress =</span> F)</span></code></pre></div>
<p><img src="_main_files/figure-html/ch5-12-1.png" width="672" /></p>
<p>We can make a few observations here:</p>
<ul>
<li><p>The various size parameters: <code>carat</code>, <code>x</code>, <code>y</code>, and <code>z</code> are all highly correlated,
as may be expected.</p></li>
<li><p>The shape of the distribution for <code>carat</code> indicates that it may be best used when
log-transformed (a left-biased distribution with a long tail).</p></li>
<li><p><code>price</code> is very highly correlated with <code>carat</code>, as might be expected from a layman’s
understanding of how diamonds are priced. Bigger is better!</p></li>
</ul>
<p>There are a few categorical variables as well that we should examine:</p>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="chapter-5.html#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(diamonds, <span class="fu">aes</span>(price, carat, <span class="at">color =</span> cut)) <span class="sc">+</span></span>
<span id="cb76-2"><a href="chapter-5.html#cb76-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb76-3"><a href="chapter-5.html#cb76-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code></pre></div>
<p><img src="_main_files/figure-html/ch5-13-1.png" width="672" /></p>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="chapter-5.html#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(diamonds, <span class="fu">aes</span>(price, carat, <span class="at">color =</span> color)) <span class="sc">+</span></span>
<span id="cb77-2"><a href="chapter-5.html#cb77-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb77-3"><a href="chapter-5.html#cb77-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code></pre></div>
<p><img src="_main_files/figure-html/ch5-14-1.png" width="672" /></p>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb78-1"><a href="chapter-5.html#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(diamonds, <span class="fu">aes</span>(price, carat, <span class="at">color =</span> clarity)) <span class="sc">+</span></span>
<span id="cb78-2"><a href="chapter-5.html#cb78-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.5</span>) <span class="sc">+</span></span>
<span id="cb78-3"><a href="chapter-5.html#cb78-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code></pre></div>
<p><img src="_main_files/figure-html/ch5-15-1.png" width="672" /></p>
<p>There appears to be <em>some</em> variation in <code>price</code>/<code>carat</code> based on these categorical
values, but it’s not extremely pronounced. The patterns are perhaps more easily
observable on the correlogram.</p>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="chapter-5.html#cb79-1" aria-hidden="true" tabindex="-1"></a>columns <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;price&quot;</span>, <span class="st">&quot;cut&quot;</span>, <span class="st">&quot;color&quot;</span>, <span class="st">&quot;clarity&quot;</span>)</span>
<span id="cb79-2"><a href="chapter-5.html#cb79-2" aria-hidden="true" tabindex="-1"></a>GGally<span class="sc">::</span><span class="fu">ggpairs</span>(diamonds, <span class="at">columns =</span> columns, <span class="at">progress =</span> F)</span></code></pre></div>
<p><img src="_main_files/figure-html/ch5-16-1.png" width="672" /></p>
<p>There appears to be <em>some</em> correlation between <code>color</code>, <code>cut</code>, and <code>clarity</code>, with the
most pronounced between <code>color</code> and <code>cut</code>. If we knew more about the diamond pricing
market, we might infer that certain cuts are preferred for certain colors of diamond,
but that’s just conjecture at this point. We’ll choose to add an interaction term for
<code>color:cut</code>, but there’s probably room for more experimentation on this point.</p>
</div>
<div id="high-leverage-points" class="section level3 hasAnchor" number="5.5.4">
<h3><span class="header-section-number">5.5.4</span> High Leverage Points<a href="chapter-5.html#high-leverage-points" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Recall, that <em>high-leverage points</em> are those observations where the observed values
fall well outside the range of the majority of the observed values. Since we only have
one continuous predictor variable (<code>carat</code>), any high-leverage points should be pretty
easy to find. (Note, recall that above we indicated a that we should log-transform
<code>carat</code> due to its distribution, so we should do that here as well).</p>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb80-1"><a href="chapter-5.html#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(diamonds, <span class="fu">aes</span>(<span class="fu">factor</span>(<span class="dv">1</span>), <span class="fu">log</span>(carat))) <span class="sc">+</span></span>
<span id="cb80-2"><a href="chapter-5.html#cb80-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>() <span class="sc">+</span></span>
<span id="cb80-3"><a href="chapter-5.html#cb80-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code></pre></div>
<p><img src="_main_files/figure-html/ch5-17-1.png" width="672" /></p>
<p>Looks like there are two values for <code>carat</code> that fall way outside the range of the
majority of the values. Let’s find them:</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="chapter-5.html#cb81-1" aria-hidden="true" tabindex="-1"></a>(diamonds</span>
<span id="cb81-2"><a href="chapter-5.html#cb81-2" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">arrange</span>(<span class="fu">desc</span>(carat))</span>
<span id="cb81-3"><a href="chapter-5.html#cb81-3" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">head</span>(<span class="dv">2</span>)</span>
<span id="cb81-4"><a href="chapter-5.html#cb81-4" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">pull</span>(carat)</span>
<span id="cb81-5"><a href="chapter-5.html#cb81-5" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">log</span>()</span>
<span id="cb81-6"><a href="chapter-5.html#cb81-6" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">round</span>(<span class="dv">2</span>))</span></code></pre></div>
<pre><code>## [1] 1.61 1.50</code></pre>
<p>Just for fun, let’s check the normal range for <code>carat</code>:</p>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="chapter-5.html#cb83-1" aria-hidden="true" tabindex="-1"></a>mean_carat <span class="ot">&lt;-</span> <span class="fu">mean</span>(<span class="fu">log</span>(diamonds<span class="sc">$</span>carat)) <span class="sc">|&gt;</span> <span class="fu">round</span>(<span class="dv">2</span>)</span>
<span id="cb83-2"><a href="chapter-5.html#cb83-2" aria-hidden="true" tabindex="-1"></a>sd_carat   <span class="ot">&lt;-</span> <span class="fu">sd</span>(<span class="fu">log</span>(diamonds<span class="sc">$</span>carat)) <span class="sc">|&gt;</span> <span class="fu">round</span>(<span class="dv">2</span>)</span>
<span id="cb83-3"><a href="chapter-5.html#cb83-3" aria-hidden="true" tabindex="-1"></a><span class="fu">paste</span>(mean_carat, <span class="st">&quot;+/-&quot;</span>, sd_carat)</span></code></pre></div>
<pre><code>## [1] &quot;-0.39 +/- 0.58&quot;</code></pre>
<p>Those values are more than 3 standard deviations away from the mean of <em>log</em> <code>carat</code>. To
be on the safe side, let’s exclude any observations where <code>log(carat)</code> lies 3 or more
standard deviations from the mean.</p>
</div>
<div id="fit-and-check" class="section level3 hasAnchor" number="5.5.5">
<h3><span class="header-section-number">5.5.5</span> Fit and Check<a href="chapter-5.html#fit-and-check" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>From exploring the dataset, I’ve decided to:</p>
<ul>
<li><p>Log-transform <code>price</code> then add each transformed price to one of 5 classes, depending
on its value.</p></li>
<li><p>Use <code>carat</code>, <code>cut</code>, <code>clarity</code>, and <code>color</code> as predictor variables.</p></li>
<li><p>Log-transform <code>carat</code> prior to training the model.</p></li>
<li><p>Remove observations where <code>log(carat)</code> is 3 or more standard deviations away from
the mean as high-leverage observations.</p></li>
<li><p>Add an interaction parameter for <code>color:cut</code>.</p></li>
</ul>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="chapter-5.html#cb85-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">800633</span>)</span>
<span id="cb85-2"><a href="chapter-5.html#cb85-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-3"><a href="chapter-5.html#cb85-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Modification to response variables should not be part of the workflow</span></span>
<span id="cb85-4"><a href="chapter-5.html#cb85-4" aria-hidden="true" tabindex="-1"></a>mod_diamonds <span class="ot">&lt;-</span> <span class="fu">mutate</span>(diamonds, <span class="at">price_cat =</span> <span class="fu">cut_interval</span>(<span class="fu">log</span>(price), <span class="dv">5</span>))</span>
<span id="cb85-5"><a href="chapter-5.html#cb85-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-6"><a href="chapter-5.html#cb85-6" aria-hidden="true" tabindex="-1"></a>mod_diamonds_split <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(mod_diamonds)</span>
<span id="cb85-7"><a href="chapter-5.html#cb85-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb85-8"><a href="chapter-5.html#cb85-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Specify the recipe, using the preparation steps described above</span></span>
<span id="cb85-9"><a href="chapter-5.html#cb85-9" aria-hidden="true" tabindex="-1"></a>(log_reg_recipe</span>
<span id="cb85-10"><a href="chapter-5.html#cb85-10" aria-hidden="true" tabindex="-1"></a>  <span class="ot">&lt;-</span> <span class="fu">recipe</span>(price_cat <span class="sc">~</span> carat <span class="sc">+</span> cut <span class="sc">+</span> color <span class="sc">+</span> clarity,</span>
<span id="cb85-11"><a href="chapter-5.html#cb85-11" aria-hidden="true" tabindex="-1"></a>            <span class="at">data =</span> mod_diamonds)</span>
<span id="cb85-12"><a href="chapter-5.html#cb85-12" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">step_log</span>(carat)</span>
<span id="cb85-13"><a href="chapter-5.html#cb85-13" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">step_filter</span>(<span class="fu">abs</span>(carat <span class="sc">-</span> <span class="fu">mean</span>(carat)) <span class="sc">&lt;</span> (<span class="fu">sd</span>(carat) <span class="sc">*</span> <span class="dv">3</span>))</span>
<span id="cb85-14"><a href="chapter-5.html#cb85-14" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">step_dummy</span>(<span class="fu">all_nominal_predictors</span>())</span>
<span id="cb85-15"><a href="chapter-5.html#cb85-15" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">step_interact</span>(price_cat <span class="sc">~</span> <span class="fu">starts_with</span>(<span class="st">&quot;color_&quot;</span>)<span class="sc">:</span><span class="fu">starts_with</span>(<span class="st">&quot;cut_&quot;</span>)))</span></code></pre></div>
<pre><code>## Recipe
## 
## Inputs:
## 
##       role #variables
##    outcome          1
##  predictor          4
## 
## Operations:
## 
## Log transformation on carat
## Row filtering using abs(carat - mean(carat)) &lt; (sd(carat) * 3)
## Dummy variables from all_nominal_predictors()
## Interactions with price_cat, starts_with(&quot;color_&quot;):starts_with(&quot;cut_&quot;)</code></pre>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb87-1"><a href="chapter-5.html#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Setup the model</span></span>
<span id="cb87-2"><a href="chapter-5.html#cb87-2" aria-hidden="true" tabindex="-1"></a>(log_reg_model</span>
<span id="cb87-3"><a href="chapter-5.html#cb87-3" aria-hidden="true" tabindex="-1"></a>  <span class="ot">&lt;-</span> <span class="fu">multinom_reg</span>()</span>
<span id="cb87-4"><a href="chapter-5.html#cb87-4" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">set_engine</span>(<span class="st">&quot;nnet&quot;</span>)</span>
<span id="cb87-5"><a href="chapter-5.html#cb87-5" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">set_mode</span>(<span class="st">&quot;classification&quot;</span>))</span></code></pre></div>
<pre><code>## Multinomial Regression Model Specification (classification)
## 
## Computational engine: nnet</code></pre>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb89-1"><a href="chapter-5.html#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Bundle the recipe and model into a workflow, fit the model</span></span>
<span id="cb89-2"><a href="chapter-5.html#cb89-2" aria-hidden="true" tabindex="-1"></a>(log_reg_workflow</span>
<span id="cb89-3"><a href="chapter-5.html#cb89-3" aria-hidden="true" tabindex="-1"></a>  <span class="ot">&lt;-</span> <span class="fu">workflow</span>()</span>
<span id="cb89-4"><a href="chapter-5.html#cb89-4" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">add_recipe</span>(log_reg_recipe)</span>
<span id="cb89-5"><a href="chapter-5.html#cb89-5" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">add_model</span>(log_reg_model)</span>
<span id="cb89-6"><a href="chapter-5.html#cb89-6" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">fit</span>(<span class="at">data =</span> <span class="fu">training</span>(mod_diamonds_split)))</span></code></pre></div>
<pre><code>## ══ Workflow [trained] ═══════════════════════════════════════════════════════════════════════════════
## Preprocessor: Recipe
## Model: multinom_reg()
## 
## ── Preprocessor ─────────────────────────────────────────────────────────────────────────────────────
## 4 Recipe Steps
## 
## • step_log()
## • step_filter()
## • step_dummy()
## • step_interact()
## 
## ── Model ────────────────────────────────────────────────────────────────────────────────────────────
## Call:
## nnet::multinom(formula = ..y ~ ., data = data, trace = FALSE)
## 
## Coefficients:
##             (Intercept)    carat    cut_1     cut_2     cut_3     cut_4   color_1     color_2
## (6.6,7.41]     14.77133 14.98926 4.106441 -3.569287 1.3668315 -2.011030 -2.848696 -0.03877709
## (7.41,8.22]    25.23687 32.12698 3.895234 -3.037634 0.5433772 -1.746210 -5.919968  0.17077340
## (8.22,9.03]    27.02919 46.56542 5.066777 -3.195376 0.9064511 -1.378375 -8.423160 -0.10510982
## (9.03,9.84]    21.85345 59.44266 7.601931 -4.935027 2.6772676 -1.714478 -9.793854 -1.65460281
##               color_3     color_4     color_5    color_6 clarity_1  clarity_2  clarity_3  clarity_4
## (6.6,7.41]  2.1058502  0.06402263 -0.39966774 -0.6704520  7.806147  0.7449121 -0.2797165  0.6140537
## (7.41,8.22] 0.8627596 -0.49520457  0.08630286 -0.1890811 15.557550  0.3599709 -0.3223965  2.0028156
## (8.22,9.03] 0.6231886 -0.06351782  0.14218674 -0.8032102 21.285218 -1.0968904  1.0169551  0.8260622
## (9.03,9.84] 0.4438435 -0.44292761  0.43035152 -1.9180478 29.222613 -5.9869350  3.7545372 -1.1978647
##              clarity_5 clarity_6 clarity_7 color_1_x_cut_1 color_1_x_cut_2 color_1_x_cut_3
## (6.6,7.41]  -0.4483736 0.3632309 0.6256839       -1.888081       -5.772038        1.358870
## (7.41,8.22] -0.5171474 0.5503920 0.8737247       -6.663059       -3.452039       -2.487619
## (8.22,9.03] -1.2763157 0.0479671 0.6268565       -6.465506       -2.468129       -2.750882
## (9.03,9.84]  0.6341891 0.9096949 1.3602075      -12.137445        2.230262       -5.166862
##             color_1_x_cut_4 color_2_x_cut_1 color_2_x_cut_2 color_2_x_cut_3 color_2_x_cut_4
## (6.6,7.41]       -2.0890335       1.5252801      -3.0902028       0.8809812       0.3365358
## (7.41,8.22]       1.4108126      -0.9267690      -1.3385217      -2.0378257       1.5823993
## (8.22,9.03]      -0.5081945      -0.7446158       0.7016114      -3.0166846       3.4134568
## (9.03,9.84]       0.2651442       1.2777073       0.2345068      -1.0267471       3.2055242
##             color_3_x_cut_1 color_3_x_cut_2 color_3_x_cut_3 color_3_x_cut_4 color_4_x_cut_1
## (6.6,7.41]       -0.7423168       -2.467593       0.3167168       0.4632866        1.991268
## (7.41,8.22]       0.6897983       -2.892903       0.5723597       0.5996124        2.938301
## (8.22,9.03]       2.5698649       -2.275121       1.6777016       1.3828688        2.764084
## (9.03,9.84]       2.3537641       -2.189823       2.9626609       1.7180650        3.093712
##             color_4_x_cut_2 color_4_x_cut_3 color_4_x_cut_4 color_5_x_cut_1 color_5_x_cut_2
## (6.6,7.41]        -4.183403      1.27063921       0.3216012       1.0628629      0.03580568
## (7.41,8.22]       -4.353914      3.34454302       0.5546513      -1.2086507      0.78604881
## (8.22,9.03]       -5.145836      3.72353328       1.4893282      -0.1674063      0.21505487
## (9.03,9.84]       -2.133068      0.02659431      -0.1138213      -2.9317166      2.95632557
##             color_5_x_cut_3 color_5_x_cut_4 color_6_x_cut_1 color_6_x_cut_2 color_6_x_cut_3
## (6.6,7.41]       -1.2692962      -0.5879730      -0.3521551      0.02457326      -1.1774001
## (7.41,8.22]       1.7574518      -0.4392463      -4.4523729      2.43067566       0.3927754
## (8.22,9.03]       2.1639698       0.2834687      -2.1473629      1.11493030       0.1150996
## (9.03,9.84]       0.8466614       0.4828583       1.4863675     -2.46947278       3.4413292
##             color_6_x_cut_4
## (6.6,7.41]        0.1110854
## (7.41,8.22]      -0.3388539
## (8.22,9.03]       0.6050693
## (9.03,9.84]      -0.7874513
## 
## Residual Deviance: 30240.06 
## AIC: 30584.06</code></pre>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb91-1"><a href="chapter-5.html#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Add predictions to training data</span></span>
<span id="cb91-2"><a href="chapter-5.html#cb91-2" aria-hidden="true" tabindex="-1"></a>log_reg_predictions <span class="ot">&lt;-</span> <span class="fu">augment</span>(log_reg_workflow, <span class="fu">testing</span>(mod_diamonds_split))</span>
<span id="cb91-3"><a href="chapter-5.html#cb91-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb91-4"><a href="chapter-5.html#cb91-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Check performance using the same set of metrics as we did previously</span></span>
<span id="cb91-5"><a href="chapter-5.html#cb91-5" aria-hidden="true" tabindex="-1"></a>eval_metrics <span class="ot">&lt;-</span> <span class="fu">metric_set</span>(</span>
<span id="cb91-6"><a href="chapter-5.html#cb91-6" aria-hidden="true" tabindex="-1"></a>  ppv,      recall, specificity, </span>
<span id="cb91-7"><a href="chapter-5.html#cb91-7" aria-hidden="true" tabindex="-1"></a>  accuracy, f_meas, kap,    </span>
<span id="cb91-8"><a href="chapter-5.html#cb91-8" aria-hidden="true" tabindex="-1"></a>  roc_auc</span>
<span id="cb91-9"><a href="chapter-5.html#cb91-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb91-10"><a href="chapter-5.html#cb91-10" aria-hidden="true" tabindex="-1"></a><span class="fu">eval_metrics</span>(</span>
<span id="cb91-11"><a href="chapter-5.html#cb91-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> log_reg_predictions, </span>
<span id="cb91-12"><a href="chapter-5.html#cb91-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">truth =</span> price_cat, </span>
<span id="cb91-13"><a href="chapter-5.html#cb91-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">estimate =</span> .pred_class, </span>
<span id="cb91-14"><a href="chapter-5.html#cb91-14" aria-hidden="true" tabindex="-1"></a>  <span class="st">`</span><span class="at">.pred_[5.79,6.6]</span><span class="st">`</span>,</span>
<span id="cb91-15"><a href="chapter-5.html#cb91-15" aria-hidden="true" tabindex="-1"></a>  <span class="st">`</span><span class="at">.pred_(6.6,7.41]</span><span class="st">`</span>,</span>
<span id="cb91-16"><a href="chapter-5.html#cb91-16" aria-hidden="true" tabindex="-1"></a>  <span class="st">`</span><span class="at">.pred_(7.41,8.22]</span><span class="st">`</span>,</span>
<span id="cb91-17"><a href="chapter-5.html#cb91-17" aria-hidden="true" tabindex="-1"></a>  <span class="st">`</span><span class="at">.pred_(8.22,9.03]</span><span class="st">`</span>,</span>
<span id="cb91-18"><a href="chapter-5.html#cb91-18" aria-hidden="true" tabindex="-1"></a>  <span class="st">`</span><span class="at">.pred_(9.03,9.84]</span><span class="st">`</span></span>
<span id="cb91-19"><a href="chapter-5.html#cb91-19" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## # A tibble: 7 × 3
##   .metric     .estimator .estimate
##   &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;
## 1 ppv         macro          0.851
## 2 recall      macro          0.842
## 3 specificity macro          0.961
## 4 accuracy    multiclass     0.847
## 5 f_meas      macro          0.846
## 6 kap         multiclass     0.806
## 7 roc_auc     hand_till      0.978</code></pre>
<p>The metrics look pretty good, let’s take a look at the confusion matrix…</p>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb93-1"><a href="chapter-5.html#cb93-1" aria-hidden="true" tabindex="-1"></a>(log_reg_predictions</span>
<span id="cb93-2"><a href="chapter-5.html#cb93-2" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">count</span>(price_cat, .pred_class)</span>
<span id="cb93-3"><a href="chapter-5.html#cb93-3" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">pivot_wider</span>(<span class="at">names_from =</span> .pred_class, <span class="at">values_from =</span> n))</span></code></pre></div>
<pre><code>## # A tibble: 5 × 6
##   price_cat   `[5.79,6.6]` `(6.6,7.41]` `(7.41,8.22]` `(8.22,9.03]` `(9.03,9.84]`
##   &lt;fct&gt;              &lt;int&gt;        &lt;int&gt;         &lt;int&gt;         &lt;int&gt;         &lt;int&gt;
## 1 [5.79,6.6]          1546          454            NA            NA            NA
## 2 (6.6,7.41]           290         2636           292            NA            NA
## 3 (7.41,8.22]            1          130          2680           233            NA
## 4 (8.22,9.03]           NA           NA           202          2984           191
## 5 (9.03,9.84]           NA           NA            NA           267          1579</code></pre>
<p>All told, our classifier seems to be working OK. Most of the time, we’re correctly
predicted the price category for each observation in the testing set, and when we
mis-classify the price category we are (with one single exception) picking the price
category above or below the true category.</p>

</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="5">
<li id="fn5"><p>Definition from <a href="https://en.wikipedia.org/wiki/Confusion_matrix">Wikipedia</a>.<a href="chapter-5.html#fnref5" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="chapter-4.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="references.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/chapters/ch05-logistic-regression.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
