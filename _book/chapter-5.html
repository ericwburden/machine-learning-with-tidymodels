<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Logistic Regression | Machine Learning with TidyModels</title>
  <meta name="description" content="This is a primer on various ML modeling techniques and the tidymodels</code>
syntax and workflow for leveraging these techniques.</p>" />
  <meta name="generator" content="bookdown 0.29 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Logistic Regression | Machine Learning with TidyModels" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is a primer on various ML modeling techniques and the tidymodels</code>
syntax and workflow for leveraging these techniques.</p>" />
  <meta name="github-repo" content="ericwburden/machine-learning-with-tidymodels" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Logistic Regression | Machine Learning with TidyModels" />
  
  <meta name="twitter:description" content="This is a primer on various ML modeling techniques and the tidymodels</code>
syntax and workflow for leveraging these techniques.</p>" />
  

<meta name="author" content="Eric Burden" />


<meta name="date" content="2022-11-03" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="chapter-4.html"/>
<link rel="next" href="references.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; } /* Alert */
code span.an { color: #008000; } /* Annotation */
code span.at { } /* Attribute */
code span.bu { } /* BuiltIn */
code span.cf { color: #0000ff; } /* ControlFlow */
code span.ch { color: #008080; } /* Char */
code span.cn { } /* Constant */
code span.co { color: #008000; } /* Comment */
code span.cv { color: #008000; } /* CommentVar */
code span.do { color: #008000; } /* Documentation */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.im { } /* Import */
code span.in { color: #008000; } /* Information */
code span.kw { color: #0000ff; } /* Keyword */
code span.op { } /* Operator */
code span.ot { color: #ff4000; } /* Other */
code span.pp { color: #ff4000; } /* Preprocessor */
code span.sc { color: #008080; } /* SpecialChar */
code span.ss { color: #008080; } /* SpecialString */
code span.st { color: #008080; } /* String */
code span.va { } /* Variable */
code span.vs { color: #008080; } /* VerbatimString */
code span.wa { color: #008000; font-weight: bold; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Notes on Tidymodels</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> About</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#ch1-software_used"><i class="fa fa-check"></i><b>1.1</b> Software Used</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="chapter-2.html"><a href="chapter-2.html"><i class="fa fa-check"></i><b>2</b> The Tidymodels Workflow</a>
<ul>
<li class="chapter" data-level="2.1" data-path="chapter-2.html"><a href="chapter-2.html#ch2-about-tidymodels"><i class="fa fa-check"></i><b>2.1</b> About Tidymodels</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="chapter-2.html"><a href="chapter-2.html#ch2-reuse-existing-data-structures"><i class="fa fa-check"></i><b>2.1.1</b> Re-use existing data structures</a></li>
<li class="chapter" data-level="2.1.2" data-path="chapter-2.html"><a href="chapter-2.html#ch2-simple-functions-with-pipes"><i class="fa fa-check"></i><b>2.1.2</b> Compose simple functions with pipes</a></li>
<li class="chapter" data-level="2.1.3" data-path="chapter-2.html"><a href="chapter-2.html#ch2-embrace-functional-programming"><i class="fa fa-check"></i><b>2.1.3</b> Embrace functional programming</a></li>
<li class="chapter" data-level="2.1.4" data-path="chapter-2.html"><a href="chapter-2.html#ch2-design-for-humans"><i class="fa fa-check"></i><b>2.1.4</b> Design for humans</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="chapter-2.html"><a href="chapter-2.html#ch2-philosophy-in-practice"><i class="fa fa-check"></i><b>2.2</b> Philosophy in Practice</a></li>
<li class="chapter" data-level="2.3" data-path="chapter-2.html"><a href="chapter-2.html#ch2-workflow-steps"><i class="fa fa-check"></i><b>2.3</b> Workflow Steps</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="chapter-2.html"><a href="chapter-2.html#ch2-data-splitting"><i class="fa fa-check"></i><b>2.3.1</b> Data Splitting</a></li>
<li class="chapter" data-level="2.3.2" data-path="chapter-2.html"><a href="chapter-2.html#ch2-data-preparation"><i class="fa fa-check"></i><b>2.3.2</b> Data Preparation</a></li>
<li class="chapter" data-level="2.3.3" data-path="chapter-2.html"><a href="chapter-2.html#ch2-model-specification"><i class="fa fa-check"></i><b>2.3.3</b> Model Specification</a></li>
<li class="chapter" data-level="2.3.4" data-path="chapter-2.html"><a href="chapter-2.html#ch2-bundling-a-workflow"><i class="fa fa-check"></i><b>2.3.4</b> Bundling a Workflow</a></li>
<li class="chapter" data-level="2.3.5" data-path="chapter-2.html"><a href="chapter-2.html#ch2-checking-results"><i class="fa fa-check"></i><b>2.3.5</b> Checking Results</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="chapter-3.html"><a href="chapter-3.html"><i class="fa fa-check"></i><b>3</b> Simple Linear Regression</a>
<ul>
<li class="chapter" data-level="3.1" data-path="chapter-3.html"><a href="chapter-3.html#ch3-description"><i class="fa fa-check"></i><b>3.1</b> Description</a></li>
<li class="chapter" data-level="3.2" data-path="chapter-3.html"><a href="chapter-3.html#ch3-how-it-works"><i class="fa fa-check"></i><b>3.2</b> How it Works</a></li>
<li class="chapter" data-level="3.3" data-path="chapter-3.html"><a href="chapter-3.html#ch3-evaluating-validity"><i class="fa fa-check"></i><b>3.3</b> Evaluating Validity</a></li>
<li class="chapter" data-level="3.4" data-path="chapter-3.html"><a href="chapter-3.html#ch3-evaluating-fit"><i class="fa fa-check"></i><b>3.4</b> Evaluating Fit</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="chapter-3.html"><a href="chapter-3.html#ch3-residual-standard-error"><i class="fa fa-check"></i><b>3.4.1</b> Residual Standard Error</a></li>
<li class="chapter" data-level="3.4.2" data-path="chapter-3.html"><a href="chapter-3.html#ch3-rsq-statistic"><i class="fa fa-check"></i><b>3.4.2</b> <span class="math inline">\(R^2\)</span> Statistic</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="chapter-3.html"><a href="chapter-3.html#ch3-example"><i class="fa fa-check"></i><b>3.5</b> Example</a></li>
<li class="chapter" data-level="3.6" data-path="chapter-3.html"><a href="chapter-3.html#ch3-considerations"><i class="fa fa-check"></i><b>3.6</b> Considerations</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="chapter-3.html"><a href="chapter-3.html#ch3-limits-of-applicability"><i class="fa fa-check"></i><b>3.6.1</b> Limits of Applicability</a></li>
<li class="chapter" data-level="3.6.2" data-path="chapter-3.html"><a href="chapter-3.html#ch3-outliers"><i class="fa fa-check"></i><b>3.6.2</b> Outliers</a></li>
<li class="chapter" data-level="3.6.3" data-path="chapter-3.html"><a href="chapter-3.html#ch3-high-leverage-points"><i class="fa fa-check"></i><b>3.6.3</b> High-leverage points</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="chapter-4.html"><a href="chapter-4.html"><i class="fa fa-check"></i><b>4</b> Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="4.1" data-path="chapter-4.html"><a href="chapter-4.html#ch4-description"><i class="fa fa-check"></i><b>4.1</b> Description</a></li>
<li class="chapter" data-level="4.2" data-path="chapter-4.html"><a href="chapter-4.html#ch4-how-it-works"><i class="fa fa-check"></i><b>4.2</b> How it Works</a></li>
<li class="chapter" data-level="4.3" data-path="chapter-4.html"><a href="chapter-4.html#ch4-evaluating-validity"><i class="fa fa-check"></i><b>4.3</b> Evaluating Validity</a></li>
<li class="chapter" data-level="4.4" data-path="chapter-4.html"><a href="chapter-4.html#ch4-identifying-important-predictors"><i class="fa fa-check"></i><b>4.4</b> Identifying Important Predictors</a></li>
<li class="chapter" data-level="4.5" data-path="chapter-4.html"><a href="chapter-4.html#ch4-evaluating-fit"><i class="fa fa-check"></i><b>4.5</b> Evaluating Fit</a></li>
<li class="chapter" data-level="4.6" data-path="chapter-4.html"><a href="chapter-4.html#ch4-example"><i class="fa fa-check"></i><b>4.6</b> Example</a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="chapter-4.html"><a href="chapter-4.html#ch-correlated-predictors"><i class="fa fa-check"></i><b>4.6.1</b> Correlated Predictors</a></li>
<li class="chapter" data-level="4.6.2" data-path="chapter-4.html"><a href="chapter-4.html#ch4-tidymodels-workflow"><i class="fa fa-check"></i><b>4.6.2</b> Tidymodels Workflow</a></li>
</ul></li>
<li class="chapter" data-level="4.7" data-path="chapter-4.html"><a href="chapter-4.html#ch4-considerations"><i class="fa fa-check"></i><b>4.7</b> Considerations</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="chapter-4.html"><a href="chapter-4.html#ch4-not-just-combining-simple-models"><i class="fa fa-check"></i><b>4.7.1</b> Not Just Combining Simple Models</a></li>
<li class="chapter" data-level="4.7.2" data-path="chapter-4.html"><a href="chapter-4.html#ch4-qualitative-variables"><i class="fa fa-check"></i><b>4.7.2</b> Qualitative Variables</a></li>
<li class="chapter" data-level="4.7.3" data-path="chapter-4.html"><a href="chapter-4.html#ch4-predictor-interactions"><i class="fa fa-check"></i><b>4.7.3</b> Predictor Interactions</a></li>
<li class="chapter" data-level="4.7.4" data-path="chapter-4.html"><a href="chapter-4.html#ch4-polynomial-regression"><i class="fa fa-check"></i><b>4.7.4</b> Polynomial Regression</a></li>
<li class="chapter" data-level="4.7.5" data-path="chapter-4.html"><a href="chapter-4.html#ch4-potential-issues"><i class="fa fa-check"></i><b>4.7.5</b> Potential Issues</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="chapter-5.html"><a href="chapter-5.html"><i class="fa fa-check"></i><b>5</b> Logistic Regression</a>
<ul>
<li class="chapter" data-level="5.1" data-path="chapter-5.html"><a href="chapter-5.html#ch5-description"><i class="fa fa-check"></i><b>5.1</b> Description</a></li>
<li class="chapter" data-level="5.2" data-path="chapter-5.html"><a href="chapter-5.html#ch5-how-it-works"><i class="fa fa-check"></i><b>5.2</b> How it Works</a></li>
<li class="chapter" data-level="5.3" data-path="chapter-5.html"><a href="chapter-5.html#ch5-evaluating-validity"><i class="fa fa-check"></i><b>5.3</b> Evaluating Validity</a></li>
<li class="chapter" data-level="5.4" data-path="chapter-5.html"><a href="chapter-5.html#ch5-evaluating-fit"><i class="fa fa-check"></i><b>5.4</b> Evaluating Fit</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="chapter-5.html"><a href="chapter-5.html#ch5-binomial-logistic-regression"><i class="fa fa-check"></i><b>5.4.1</b> Binomial Logistic Regression</a></li>
<li class="chapter" data-level="5.4.2" data-path="chapter-5.html"><a href="chapter-5.html#ch5-multinomial-logistic-regression"><i class="fa fa-check"></i><b>5.4.2</b> Multinomial Logistic Regression</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="chapter-5.html"><a href="chapter-5.html#ch5-example"><i class="fa fa-check"></i><b>5.5</b> Example</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>6</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Machine Learning with TidyModels</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="chapter-5" class="section level1 hasAnchor" number="5">
<h1><span class="header-section-number">Chapter 5</span> Logistic Regression<a href="chapter-5.html#chapter-5" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="ch5-description" class="section level2 hasAnchor" number="5.1">
<h2><span class="header-section-number">5.1</span> Description<a href="chapter-5.html#ch5-description" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>An approach for predicting a the probability that response value <span class="math inline">\(Y\)</span> belongs to a
particular <em>category</em> based on one or more predictor values <span class="math inline">\(X_1, X_2, ... X_n\)</span>. The
probability will always lie between 0 (no chance) and 1 (absolute certainty) and can be
given by the following <em>logistic function</em> for the case with a single predictor
variable:</p>
<p><span class="math display">\[p(X) = \frac{e^{\beta_0 + \beta_1X}}{1 + e^{\beta_0 + \beta_1X}}\]</span> where
<span class="math inline">\(p(X) = Pr(Y = category|X)\)</span>, which can be read as “the probability that <span class="math inline">\(Y\)</span> is
<code>category</code> given <span class="math inline">\(X\)</span>.</p>
<p>Unlike a linear function, this <em>logistic</em> function will not indicate a probability of an
observation belonging to a particular category as negative or greater than 1.
Determining whether to treat a particular observation as belonging to a particular
category can be made on the basis of the probability returned by this function. It may
be reasonable to use a 50% threshold in many cases (<span class="math inline">\(p(X) &gt; 0.5\)</span>), but an analyst may
want to be adjust this threshold to meet business needs. You may wish to raise the
threshold to reduce false positive classifications or lower it to reduce false negative
classifications.</p>
</div>
<div id="ch5-how-it-works" class="section level2 hasAnchor" number="5.2">
<h2><span class="header-section-number">5.2</span> How it Works<a href="chapter-5.html#ch5-how-it-works" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A careful observer may not some similarities in the exponents of the formula above and
the linear formula discussed in previous chapters. A bit of manipulation yields:</p>
<p><span class="math display">\[\frac{p(X)}{1 - p(X)} = e^{\beta_0 + \beta_1X}\]</span></p>
<p>where the <span class="math inline">\(\frac{p(X)}{1 - p(X)}\)</span> term is labeled as the <em>odds</em> of the event, such that
an <em>odds</em> of <span class="math inline">\(1/4\)</span> yields <span class="math inline">\(p(X) = 0.2\)</span> and an <em>odds</em> of <span class="math inline">\(9\)</span> yields <span class="math inline">\(p(X) = 0.9\)</span>. You can
confirm this by noting that <span class="math inline">\(\frac{0.9}{1 - 0.9} = 9\)</span>. Taking the logarithm of both
sides yields:</p>
<p><span class="math display">\[\ln{ \left( \frac{p(X)}{1 - p(X)} \right) } = \beta_0 + \beta_1X\]</span></p>
<p>The left-hand side of that equation is called the <em>log odds</em> or <em>logit</em>. Now, our
equation looks <em>eerily</em> similar to the linear equation because, in fact, the
relationship between “the log odds that the response falls into a certain category given
<span class="math inline">\(X\)</span>” and <span class="math inline">\(X\)</span> is linear. That is, for one unit change in <span class="math inline">\(X\)</span>, the log odds that the
response falls into the indicated category changes by a constant amount <span class="math inline">\(\beta_1\)</span>. This
behavior can be extended to the case of multiple predictor variables in a manner
analogous to what we have seen for <a href="chapter-4.html#chapter-4">Linear Regression</a>:</p>
<p><span class="math display">\[\ln{ \left( \frac{p(X)}{1 - p(X)} \right) } = \beta_0 + \beta_1x_1 + \,... \, + \beta_px_p\]</span></p>
<p>This model can also be extended to the case where there are more than two response
categories, known as a <em>multinomial logistic regression</em> model, like so (with a single
predictor for simplicity):</p>
<p><span class="math display">\[\ln{ \left( \frac{Pr(Y=k|X)}{Pr(Y=K|X)} \right) } = \beta_0 + \beta_1X\]</span> To do this,
given that there are <span class="math inline">\(K\)</span> possible values for <span class="math inline">\(Y\)</span>, one possible <span class="math inline">\(K\)</span> is chosen as the
default, or <em>baseline</em> value. Consider the example of a model to classify flower species
using the <code>iris</code> data set.</p>
<table>
<caption><span id="tab:unnamed-chunk-13">Table 5.1: </span>Data summary</caption>
<tbody>
<tr class="odd">
<td align="left">Name</td>
<td align="left">iris</td>
</tr>
<tr class="even">
<td align="left">Number of rows</td>
<td align="left">150</td>
</tr>
<tr class="odd">
<td align="left">Number of columns</td>
<td align="left">5</td>
</tr>
<tr class="even">
<td align="left">_______________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Column type frequency:</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">factor</td>
<td align="left">1</td>
</tr>
<tr class="odd">
<td align="left">numeric</td>
<td align="left">4</td>
</tr>
<tr class="even">
<td align="left">________________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Group variables</td>
<td align="left">None</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: factor</strong></p>
<table style="width:100%;">
<colgroup>
<col width="17%" />
<col width="12%" />
<col width="17%" />
<col width="9%" />
<col width="11%" />
<col width="32%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="left">ordered</th>
<th align="right">n_unique</th>
<th align="left">top_counts</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Species</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="left">FALSE</td>
<td align="right">3</td>
<td align="left">set: 50, ver: 50, vir: 50</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table style="width:100%;">
<colgroup>
<col width="18%" />
<col width="13%" />
<col width="18%" />
<col width="6%" />
<col width="6%" />
<col width="5%" />
<col width="5%" />
<col width="6%" />
<col width="5%" />
<col width="6%" />
<col width="7%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="right">p0</th>
<th align="right">p25</th>
<th align="right">p50</th>
<th align="right">p75</th>
<th align="right">p100</th>
<th align="left">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Sepal.Length</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">5.84</td>
<td align="right">0.83</td>
<td align="right">4.3</td>
<td align="right">5.1</td>
<td align="right">5.80</td>
<td align="right">6.4</td>
<td align="right">7.9</td>
<td align="left">▆▇▇▅▂</td>
</tr>
<tr class="even">
<td align="left">Sepal.Width</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">3.06</td>
<td align="right">0.44</td>
<td align="right">2.0</td>
<td align="right">2.8</td>
<td align="right">3.00</td>
<td align="right">3.3</td>
<td align="right">4.4</td>
<td align="left">▁▆▇▂▁</td>
</tr>
<tr class="odd">
<td align="left">Petal.Length</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">3.76</td>
<td align="right">1.77</td>
<td align="right">1.0</td>
<td align="right">1.6</td>
<td align="right">4.35</td>
<td align="right">5.1</td>
<td align="right">6.9</td>
<td align="left">▇▁▆▇▂</td>
</tr>
<tr class="even">
<td align="left">Petal.Width</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">1.20</td>
<td align="right">0.76</td>
<td align="right">0.1</td>
<td align="right">0.3</td>
<td align="right">1.30</td>
<td align="right">1.8</td>
<td align="right">2.5</td>
<td align="left">▇▁▇▅▃</td>
</tr>
</tbody>
</table>
<p>If you are fitting a logistic regression to the <code>iris</code> data set to predict species, you
may set the <em>baseline</em> to be ‘virginica’. The choice of baseline is not important for
fitting the model, but it is important for interpreting the estimated <span class="math inline">\(\beta\)</span>
coefficients, as <span class="math inline">\(Pr(Y = k|X)\)</span> is read as the probability that <span class="math inline">\(Y\)</span> is some value other
than the baseline <span class="math inline">\(k\)</span> given <span class="math inline">\(X\)</span> and <span class="math inline">\(Pr(Y=K|X)\)</span> is the probability that <span class="math inline">\(Y\)</span> is the
baseline value <span class="math inline">\(K\)</span> given <span class="math inline">\(X\)</span>. In other works, the left-hand side is the _log odds of
<span class="math inline">\(k\)</span> versus <span class="math inline">\(K\)</span> given <span class="math inline">\(X\)</span>. This is an interesting point, but not entirely impactful, as
inferences or predictions based on this kind of model will be the same. Finally, this
expression can be extended to the case of multiple response and predictor variables like
so:</p>
<p><span class="math display">\[\ln{ \left( \frac{Pr(Y=k|X=x)}{Pr(Y=K|X=x)} \right) } = \beta_0 + \beta_1x_1 + \, ... \, + \beta_px_p\]</span></p>
<p>As an alternative to choosing a baseline category, the <em>softmax</em> coding of a logistic
regression model treats all <span class="math inline">\(K\)</span> classes symmetrically, such that the log odds ratio
between one categorical value <span class="math inline">\(k\)</span> and another <span class="math inline">\(k&#39;\)</span> can be represented as:</p>
<p><span class="math display">\[
ln{\left( \frac{Pr(Y=k|X=x}{Pr(Y=k&#39;|X=x)} \right) = (\beta_{k0} - \beta_{k&#39;0}) + (\beta_{k1} - \beta{k&#39;1})x_1 + \, ... \, + (\beta_{kp} - \beta_{k&#39;p})x_p}
\]</span></p>
<p>Similarly to the linear case, the fit to a logistic model can be fit by an equation.
Instead of the least squares method, logistic models are fit by a <em>maximum likelihood</em>
method. In the simple case with one predictor and a binary response variable, the
_maximum likelihood function_ attempts to estimate <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> in such a
way that the predicted probability <span class="math inline">\(\hat{p}(x_i)\)</span> matches the observed result as much as
possible. This means that, when <span class="math inline">\(Y\)</span> == <code>category</code> <span class="math inline">\(\hat{p}(x_i)\)</span> should be very close to
1 and when <span class="math inline">\(Y\)</span> != <code>category</code> <span class="math inline">\(\hat{p}(x_i)\)</span> should be very close to 0. This is
accomplished using a <em>likelihood function</em> of the form:</p>
<p><span class="math display">\[\ell(\beta_0, \beta_1) = \prod_{i:y_i = 1}{p(x_i)} \prod_{i&#39;:y_{i&#39;}=0}{(1 - p(x_{i&#39;}))}\]</span></p>
</div>
<div id="ch5-evaluating-validity" class="section level2 hasAnchor" number="5.3">
<h2><span class="header-section-number">5.3</span> Evaluating Validity<a href="chapter-5.html#ch5-evaluating-validity" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>As can be seen from the underlying math, there are several assumptions inherent in a
logistic regression model, regardless of the number of predictor variables or response
categories:</p>
<ul>
<li><p>Since the contribution by each set of predictors in each observation is calculated
independently for each response, it is assume that <em>each observation is
independent</em>.</p></li>
<li><p>Each predictor variable is assumed to be independent as well, that is, there is no
<a href="chapter-4.html#ch4-collinearity">collinearity</a> between predictors. This can be detected through
exploratory visualization using a scatterplot matrix or by calculating <em>variance
inflation factors</em> via <code>car::vif</code> or other methods.</p></li>
<li><p>Just as with linear regression models, the goodness-of-fit can be negatively
impacted by <a href="chapter-3.html#ch3-outliers">outliers</a> or <a href="chapter-3.html#ch3-high-leverage-points">high-leverage
points</a>.</p></li>
<li><p>Finally, as has been demonstrated, logistic regression assumes a linear relationship
between the log odds of the response belonging to a given category and the predictor
variables. This can be a bit more complicated to assess than in the linear case, but
a Box-Tidwell test (<code>car::boxTidwell</code>) or scatter plot can help. These methods are
demonstrated in the <a href="ch5-example">Example</a>.</p></li>
</ul>
</div>
<div id="ch5-evaluating-fit" class="section level2 hasAnchor" number="5.4">
<h2><span class="header-section-number">5.4</span> Evaluating Fit<a href="chapter-5.html#ch5-evaluating-fit" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="ch5-binomial-logistic-regression" class="section level3 hasAnchor" number="5.4.1">
<h3><span class="header-section-number">5.4.1</span> Binomial Logistic Regression<a href="chapter-5.html#ch5-binomial-logistic-regression" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>There are a variety of methods for evaluating the fit of a logistic regression. Unlike a
linear regression on a quantitative response, the ultimate output of a classification
model (such as a logistic regression) cannot be easily characterized by how <em>close</em> the
individual predicted response is to an observed response, in general, because the
response either <em>is</em> or <em>is not</em> classified correctly. Instead, population-wide measures
such as a <em>confusion matrix</em><a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a> can be used. Here’s what that looks like for a binomial
logistic regression on the <code>iris</code> data set, determining whether a particular flower is
of the <em>setosa</em> species.</p>
<div class="sourceCode" id="cb43"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb43-1"><a href="chapter-5.html#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">6047</span>)</span>
<span id="cb43-2"><a href="chapter-5.html#cb43-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb43-3"><a href="chapter-5.html#cb43-3" aria-hidden="true" tabindex="-1"></a><span class="co"># I&#39;m going to start by switching around the classes on a few of the</span></span>
<span id="cb43-4"><a href="chapter-5.html#cb43-4" aria-hidden="true" tabindex="-1"></a><span class="co"># observations, just to make the confusion matrix more interesting. </span></span>
<span id="cb43-5"><a href="chapter-5.html#cb43-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Otherwise, our classifier will be _too_ good.</span></span>
<span id="cb43-6"><a href="chapter-5.html#cb43-6" aria-hidden="true" tabindex="-1"></a>(iris_data</span>
<span id="cb43-7"><a href="chapter-5.html#cb43-7" aria-hidden="true" tabindex="-1"></a>  <span class="ot">&lt;-</span> iris</span>
<span id="cb43-8"><a href="chapter-5.html#cb43-8" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">mutate</span>(</span>
<span id="cb43-9"><a href="chapter-5.html#cb43-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">replace =</span> <span class="fu">sample</span>(Species, <span class="fu">n</span>()),</span>
<span id="cb43-10"><a href="chapter-5.html#cb43-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">Species =</span> <span class="fu">if_else</span>(<span class="fu">runif</span>(<span class="fu">n</span>(), <span class="dv">0</span>, <span class="dv">1</span>) <span class="sc">&gt;</span> .<span class="dv">15</span>, Species, replace),</span>
<span id="cb43-11"><a href="chapter-5.html#cb43-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">setosa  =</span> <span class="fu">factor</span>(Species <span class="sc">==</span> <span class="st">&quot;setosa&quot;</span>, <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">&quot;TRUE&quot;</span>, <span class="st">&quot;FALSE&quot;</span>)),</span>
<span id="cb43-12"><a href="chapter-5.html#cb43-12" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb43-13"><a href="chapter-5.html#cb43-13" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">select</span>(Species, setosa, <span class="fu">matches</span>(<span class="st">&quot;(Length|Width)$&quot;</span>)))</span></code></pre></div>
<pre><code>##        Species setosa Sepal.Length Sepal.Width Petal.Length Petal.Width
## 1       setosa   TRUE          5.1         3.5          1.4         0.2
## 2       setosa   TRUE          4.9         3.0          1.4         0.2
## 3       setosa   TRUE          4.7         3.2          1.3         0.2
## 4       setosa   TRUE          4.6         3.1          1.5         0.2
## 5       setosa   TRUE          5.0         3.6          1.4         0.2
## 6       setosa   TRUE          5.4         3.9          1.7         0.4
## 7       setosa   TRUE          4.6         3.4          1.4         0.3
## 8       setosa   TRUE          5.0         3.4          1.5         0.2
## 9       setosa   TRUE          4.4         2.9          1.4         0.2
## 10      setosa   TRUE          4.9         3.1          1.5         0.1
## 11      setosa   TRUE          5.4         3.7          1.5         0.2
## 12      setosa   TRUE          4.8         3.4          1.6         0.2
## 13      setosa   TRUE          4.8         3.0          1.4         0.1
## 14      setosa   TRUE          4.3         3.0          1.1         0.1
## 15      setosa   TRUE          5.8         4.0          1.2         0.2
## 16      setosa   TRUE          5.7         4.4          1.5         0.4
## 17      setosa   TRUE          5.4         3.9          1.3         0.4
## 18      setosa   TRUE          5.1         3.5          1.4         0.3
## 19      setosa   TRUE          5.7         3.8          1.7         0.3
## 20      setosa   TRUE          5.1         3.8          1.5         0.3
## 21  versicolor  FALSE          5.4         3.4          1.7         0.2
## 22      setosa   TRUE          5.1         3.7          1.5         0.4
## 23      setosa   TRUE          4.6         3.6          1.0         0.2
## 24      setosa   TRUE          5.1         3.3          1.7         0.5
## 25      setosa   TRUE          4.8         3.4          1.9         0.2
## 26      setosa   TRUE          5.0         3.0          1.6         0.2
## 27  versicolor  FALSE          5.0         3.4          1.6         0.4
## 28      setosa   TRUE          5.2         3.5          1.5         0.2
## 29      setosa   TRUE          5.2         3.4          1.4         0.2
## 30   virginica  FALSE          4.7         3.2          1.6         0.2
## 31      setosa   TRUE          4.8         3.1          1.6         0.2
## 32      setosa   TRUE          5.4         3.4          1.5         0.4
## 33      setosa   TRUE          5.2         4.1          1.5         0.1
## 34      setosa   TRUE          5.5         4.2          1.4         0.2
## 35  versicolor  FALSE          4.9         3.1          1.5         0.2
## 36      setosa   TRUE          5.0         3.2          1.2         0.2
## 37   virginica  FALSE          5.5         3.5          1.3         0.2
## 38      setosa   TRUE          4.9         3.6          1.4         0.1
## 39      setosa   TRUE          4.4         3.0          1.3         0.2
## 40      setosa   TRUE          5.1         3.4          1.5         0.2
## 41      setosa   TRUE          5.0         3.5          1.3         0.3
## 42      setosa   TRUE          4.5         2.3          1.3         0.3
## 43      setosa   TRUE          4.4         3.2          1.3         0.2
## 44      setosa   TRUE          5.0         3.5          1.6         0.6
## 45      setosa   TRUE          5.1         3.8          1.9         0.4
## 46      setosa   TRUE          4.8         3.0          1.4         0.3
## 47      setosa   TRUE          5.1         3.8          1.6         0.2
## 48      setosa   TRUE          4.6         3.2          1.4         0.2
## 49      setosa   TRUE          5.3         3.7          1.5         0.2
## 50      setosa   TRUE          5.0         3.3          1.4         0.2
## 51  versicolor  FALSE          7.0         3.2          4.7         1.4
## 52  versicolor  FALSE          6.4         3.2          4.5         1.5
## 53  versicolor  FALSE          6.9         3.1          4.9         1.5
## 54  versicolor  FALSE          5.5         2.3          4.0         1.3
## 55  versicolor  FALSE          6.5         2.8          4.6         1.5
## 56   virginica  FALSE          5.7         2.8          4.5         1.3
## 57  versicolor  FALSE          6.3         3.3          4.7         1.6
## 58  versicolor  FALSE          4.9         2.4          3.3         1.0
## 59  versicolor  FALSE          6.6         2.9          4.6         1.3
## 60  versicolor  FALSE          5.2         2.7          3.9         1.4
## 61  versicolor  FALSE          5.0         2.0          3.5         1.0
## 62  versicolor  FALSE          5.9         3.0          4.2         1.5
## 63   virginica  FALSE          6.0         2.2          4.0         1.0
## 64  versicolor  FALSE          6.1         2.9          4.7         1.4
## 65  versicolor  FALSE          5.6         2.9          3.6         1.3
## 66  versicolor  FALSE          6.7         3.1          4.4         1.4
## 67  versicolor  FALSE          5.6         3.0          4.5         1.5
## 68  versicolor  FALSE          5.8         2.7          4.1         1.0
## 69  versicolor  FALSE          6.2         2.2          4.5         1.5
## 70  versicolor  FALSE          5.6         2.5          3.9         1.1
## 71  versicolor  FALSE          5.9         3.2          4.8         1.8
## 72  versicolor  FALSE          6.1         2.8          4.0         1.3
## 73  versicolor  FALSE          6.3         2.5          4.9         1.5
## 74  versicolor  FALSE          6.1         2.8          4.7         1.2
## 75  versicolor  FALSE          6.4         2.9          4.3         1.3
## 76  versicolor  FALSE          6.6         3.0          4.4         1.4
## 77  versicolor  FALSE          6.8         2.8          4.8         1.4
## 78  versicolor  FALSE          6.7         3.0          5.0         1.7
## 79  versicolor  FALSE          6.0         2.9          4.5         1.5
## 80  versicolor  FALSE          5.7         2.6          3.5         1.0
## 81  versicolor  FALSE          5.5         2.4          3.8         1.1
## 82  versicolor  FALSE          5.5         2.4          3.7         1.0
## 83  versicolor  FALSE          5.8         2.7          3.9         1.2
## 84  versicolor  FALSE          6.0         2.7          5.1         1.6
## 85  versicolor  FALSE          5.4         3.0          4.5         1.5
## 86  versicolor  FALSE          6.0         3.4          4.5         1.6
## 87  versicolor  FALSE          6.7         3.1          4.7         1.5
## 88  versicolor  FALSE          6.3         2.3          4.4         1.3
## 89  versicolor  FALSE          5.6         3.0          4.1         1.3
## 90  versicolor  FALSE          5.5         2.5          4.0         1.3
## 91  versicolor  FALSE          5.5         2.6          4.4         1.2
## 92  versicolor  FALSE          6.1         3.0          4.6         1.4
## 93  versicolor  FALSE          5.8         2.6          4.0         1.2
## 94  versicolor  FALSE          5.0         2.3          3.3         1.0
## 95  versicolor  FALSE          5.6         2.7          4.2         1.3
## 96  versicolor  FALSE          5.7         3.0          4.2         1.2
## 97  versicolor  FALSE          5.7         2.9          4.2         1.3
## 98   virginica  FALSE          6.2         2.9          4.3         1.3
## 99  versicolor  FALSE          5.1         2.5          3.0         1.1
## 100 versicolor  FALSE          5.7         2.8          4.1         1.3
## 101  virginica  FALSE          6.3         3.3          6.0         2.5
## 102  virginica  FALSE          5.8         2.7          5.1         1.9
## 103  virginica  FALSE          7.1         3.0          5.9         2.1
## 104  virginica  FALSE          6.3         2.9          5.6         1.8
## 105  virginica  FALSE          6.5         3.0          5.8         2.2
## 106  virginica  FALSE          7.6         3.0          6.6         2.1
## 107     setosa   TRUE          4.9         2.5          4.5         1.7
## 108  virginica  FALSE          7.3         2.9          6.3         1.8
## 109  virginica  FALSE          6.7         2.5          5.8         1.8
## 110  virginica  FALSE          7.2         3.6          6.1         2.5
## 111 versicolor  FALSE          6.5         3.2          5.1         2.0
## 112  virginica  FALSE          6.4         2.7          5.3         1.9
## 113  virginica  FALSE          6.8         3.0          5.5         2.1
## 114  virginica  FALSE          5.7         2.5          5.0         2.0
## 115  virginica  FALSE          5.8         2.8          5.1         2.4
## 116  virginica  FALSE          6.4         3.2          5.3         2.3
## 117  virginica  FALSE          6.5         3.0          5.5         1.8
## 118     setosa   TRUE          7.7         3.8          6.7         2.2
## 119     setosa   TRUE          7.7         2.6          6.9         2.3
## 120  virginica  FALSE          6.0         2.2          5.0         1.5
## 121  virginica  FALSE          6.9         3.2          5.7         2.3
## 122  virginica  FALSE          5.6         2.8          4.9         2.0
## 123  virginica  FALSE          7.7         2.8          6.7         2.0
## 124  virginica  FALSE          6.3         2.7          4.9         1.8
## 125  virginica  FALSE          6.7         3.3          5.7         2.1
## 126  virginica  FALSE          7.2         3.2          6.0         1.8
## 127  virginica  FALSE          6.2         2.8          4.8         1.8
## 128  virginica  FALSE          6.1         3.0          4.9         1.8
## 129  virginica  FALSE          6.4         2.8          5.6         2.1
## 130  virginica  FALSE          7.2         3.0          5.8         1.6
## 131  virginica  FALSE          7.4         2.8          6.1         1.9
## 132  virginica  FALSE          7.9         3.8          6.4         2.0
## 133  virginica  FALSE          6.4         2.8          5.6         2.2
## 134  virginica  FALSE          6.3         2.8          5.1         1.5
## 135  virginica  FALSE          6.1         2.6          5.6         1.4
## 136  virginica  FALSE          7.7         3.0          6.1         2.3
## 137  virginica  FALSE          6.3         3.4          5.6         2.4
## 138  virginica  FALSE          6.4         3.1          5.5         1.8
## 139  virginica  FALSE          6.0         3.0          4.8         1.8
## 140  virginica  FALSE          6.9         3.1          5.4         2.1
## 141  virginica  FALSE          6.7         3.1          5.6         2.4
## 142  virginica  FALSE          6.9         3.1          5.1         2.3
## 143  virginica  FALSE          5.8         2.7          5.1         1.9
## 144  virginica  FALSE          6.8         3.2          5.9         2.3
## 145  virginica  FALSE          6.7         3.3          5.7         2.5
## 146  virginica  FALSE          6.7         3.0          5.2         2.3
## 147  virginica  FALSE          6.3         2.5          5.0         1.9
## 148 versicolor  FALSE          6.5         3.0          5.2         2.0
## 149  virginica  FALSE          6.2         3.4          5.4         2.3
## 150  virginica  FALSE          5.9         3.0          5.1         1.8</code></pre>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="chapter-5.html#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="co"># This recipe assumes that `Species` is predicted by all other values,</span></span>
<span id="cb45-2"><a href="chapter-5.html#cb45-2" aria-hidden="true" tabindex="-1"></a><span class="co"># creates interaction terms, and normalizes all the numeric predictors.</span></span>
<span id="cb45-3"><a href="chapter-5.html#cb45-3" aria-hidden="true" tabindex="-1"></a>(iris_recipe</span>
<span id="cb45-4"><a href="chapter-5.html#cb45-4" aria-hidden="true" tabindex="-1"></a>  <span class="ot">&lt;-</span> <span class="fu">recipe</span>(setosa <span class="sc">~</span> ., <span class="at">data =</span> iris_data)</span>
<span id="cb45-5"><a href="chapter-5.html#cb45-5" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">step_rm</span>(Species) <span class="co"># no cheating!</span></span>
<span id="cb45-6"><a href="chapter-5.html#cb45-6" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">step_interact</span>(setosa <span class="sc">~</span> Sepal.Length<span class="sc">:</span>Sepal.Width)</span>
<span id="cb45-7"><a href="chapter-5.html#cb45-7" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">step_interact</span>(setosa <span class="sc">~</span> Petal.Length<span class="sc">:</span>Petal.Width)</span>
<span id="cb45-8"><a href="chapter-5.html#cb45-8" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">step_normalize</span>(<span class="fu">all_numeric_predictors</span>()))</span></code></pre></div>
<pre><code>## Recipe
## 
## Inputs:
## 
##       role #variables
##    outcome          1
##  predictor          5
## 
## Operations:
## 
## Variables removed Species
## Interactions with setosa, Sepal.Length:Sepal.Width
## Interactions with setosa, Petal.Length:Petal.Width
## Centering and scaling for all_numeric_predictors()</code></pre>
<div class="sourceCode" id="cb47"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb47-1"><a href="chapter-5.html#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Specify the model</span></span>
<span id="cb47-2"><a href="chapter-5.html#cb47-2" aria-hidden="true" tabindex="-1"></a>(iris_model</span>
<span id="cb47-3"><a href="chapter-5.html#cb47-3" aria-hidden="true" tabindex="-1"></a>  <span class="ot">&lt;-</span> <span class="fu">logistic_reg</span>()</span>
<span id="cb47-4"><a href="chapter-5.html#cb47-4" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">set_engine</span>(<span class="st">&quot;glm&quot;</span>)</span>
<span id="cb47-5"><a href="chapter-5.html#cb47-5" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">set_mode</span>(<span class="st">&quot;classification&quot;</span>))</span></code></pre></div>
<pre><code>## Logistic Regression Model Specification (classification)
## 
## Computational engine: glm</code></pre>
<div class="sourceCode" id="cb49"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb49-1"><a href="chapter-5.html#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Bundle into a workflow (with fit)</span></span>
<span id="cb49-2"><a href="chapter-5.html#cb49-2" aria-hidden="true" tabindex="-1"></a>(iris_workflow</span>
<span id="cb49-3"><a href="chapter-5.html#cb49-3" aria-hidden="true" tabindex="-1"></a>  <span class="ot">&lt;-</span> <span class="fu">workflow</span>()</span>
<span id="cb49-4"><a href="chapter-5.html#cb49-4" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">add_recipe</span>(iris_recipe)</span>
<span id="cb49-5"><a href="chapter-5.html#cb49-5" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">add_model</span>(iris_model)</span>
<span id="cb49-6"><a href="chapter-5.html#cb49-6" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">fit</span>(<span class="at">data =</span> iris_data))</span></code></pre></div>
<pre><code>## ══ Workflow [trained] ══════════════════════════════════════════════════════════════════════════════
## Preprocessor: Recipe
## Model: logistic_reg()
## 
## ── Preprocessor ────────────────────────────────────────────────────────────────────────────────────
## 4 Recipe Steps
## 
## • step_rm()
## • step_interact()
## • step_interact()
## • step_normalize()
## 
## ── Model ───────────────────────────────────────────────────────────────────────────────────────────
## 
## Call:  stats::glm(formula = ..y ~ ., family = stats::binomial, data = data)
## 
## Coefficients:
##                (Intercept)                Sepal.Length                 Sepal.Width  
##                     1.9093                      1.8128                     -0.5969  
##               Petal.Length                 Petal.Width  Sepal.Length_x_Sepal.Width  
##                     2.4619                      7.7695                     -0.2847  
## Petal.Length_x_Petal.Width  
##                    -9.3748  
## 
## Degrees of Freedom: 149 Total (i.e. Null);  143 Residual
## Null Deviance:       188.1 
## Residual Deviance: 51.93     AIC: 65.93</code></pre>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="chapter-5.html#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Add predictions to the input data</span></span>
<span id="cb51-2"><a href="chapter-5.html#cb51-2" aria-hidden="true" tabindex="-1"></a>iris_predictions <span class="ot">&lt;-</span> <span class="fu">augment</span>(iris_workflow, iris_data)</span>
<span id="cb51-3"><a href="chapter-5.html#cb51-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-4"><a href="chapter-5.html#cb51-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a confusion matrix (table)</span></span>
<span id="cb51-5"><a href="chapter-5.html#cb51-5" aria-hidden="true" tabindex="-1"></a>(confusion_matrix</span>
<span id="cb51-6"><a href="chapter-5.html#cb51-6" aria-hidden="true" tabindex="-1"></a>  <span class="ot">&lt;-</span> iris_predictions</span>
<span id="cb51-7"><a href="chapter-5.html#cb51-7" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">count</span>(setosa, .pred_class)</span>
<span id="cb51-8"><a href="chapter-5.html#cb51-8" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">pivot_wider</span>(<span class="at">names_from =</span> .pred_class, <span class="at">values_from =</span> n))</span></code></pre></div>
<pre><code>## # A tibble: 2 × 3
##   setosa `TRUE` `FALSE`
##   &lt;fct&gt;   &lt;int&gt;   &lt;int&gt;
## 1 TRUE       45       3
## 2 FALSE       5      97</code></pre>
<p>In this binary case, the results can be classified in four different ways:</p>
<ul>
<li><p>A <em>true positive</em> [<span class="math inline">\(TP\)</span>] is a case where the observed value is ‘true’ and the
predicted value is ‘true’.</p></li>
<li><p>A <em>true negative</em> [<span class="math inline">\(TN\)</span>] is a case where the observed value is ‘false’ and the
predicted value is ‘false’.</p></li>
<li><p>A <em>false positive</em> [<span class="math inline">\(FP\)</span>] is a case where the observed value is ‘false’ and the
predicted value is ‘true’.</p></li>
<li><p>A <em>false negative</em> [<span class="math inline">\(FN\)</span>] is a case where the observed value is ‘true’ and the
predicted value is ‘false’.</p></li>
</ul>
<p>The counts of observations in these four ‘buckets’ can be used to calculate a variety of
useful measures:</p>
<ul>
<li><p><em>Precision</em> [<span class="math inline">\(TP/(TP + FP)\)</span>] is defined as the proportion of predicted positives
that are actually positive. Also called <em>positive predictive value</em>. Answers the
question: “Of all the flowers the model predicted to be <em>setosa</em>, what fraction
actually were?”</p></li>
<li><p><em>Recall</em> [<span class="math inline">\(TP/(TP + FN)\)</span>] is defined as the proportion of positive results out of
the number of samples which were actually positive. Also called <em>sensitivity</em>.
Answers the question: “Of all the flowers that are actually <em>setosa</em>, what fraction
did the model identify?”</p></li>
<li><p><em>Specificity</em> [<span class="math inline">\(TN/(TN + FP)\)</span>] is defined as the proportion of negative results out
of the number of samples which were actually negative. Answers the question: “Of all
flowers that were <strong>not</strong> <em>setosa</em>, what fraction did the model identify?”</p></li>
<li><p><em>Accuracy</em> [<span class="math inline">\((TP + TN)/(TP + TN + FP + FN)\)</span>] is the percentage of labels predicted
accurately for a sample. Answers the question: “Of all the observations, what
fraction were correctly classified?”</p></li>
<li><p><em>F Measure</em> is a weighted average of the precision and recall, with best 1 and worst
being 0.</p></li>
<li><p><em>Cohen’s Kappa</em> has other uses, but when determining the performance of a
classification model it provides an estimate of how much better the observed
accuracy (calculated as shown above) is than the expected accuracy. For example, if
the expected accuracy is 50% (random chance) and the observed accuracy is 95%,
<span class="math inline">\(\kappa\)</span> will be 0.90. This is especially useful when the class distribution is
skewed. Kappa can be calculated as shown:</p>
<p><span class="math display">\[\begin{align}
observations &amp;= n = TP + TN + FP + FN \\
accuracy_{obs} &amp;= \frac{TP + TN}{n}\\
accuracy_{exp} &amp;= \left(\frac{TP * FP}{obs} + \frac{TN * FN}{obs}\right) \div n\\
\kappa &amp;= \frac{accuracy_{obs} - accuracy{exp}}{1 - accuracy_{exp}}
\end{align}\]</span></p></li>
</ul>
<p>As described in <a href="chapter-5.html#ch5-how-it-works">How it Works</a>, a logistic regression model doesn’t
<em>exactly</em> predict the class of each observation, but a set of probabilities that the
observation belongs to each class. In the binary case, these are the probability that
the observed class is ‘true’ ($p(X)$) and the probability that it is ‘false’ ($1 -
p(X)$). By default, if <span class="math inline">\(p(X) &gt; 0.5\)</span>, then the predicted class will be ‘true’. This
threshold can be manipulated in order to further evaluate the model fit. By plotting the
<em>sensitivity</em> against [1 - <em>specificity</em>] for a range of threshold values, you get a
<em>received operator characteristic</em> (ROC) chart:</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="chapter-5.html#cb53-1" aria-hidden="true" tabindex="-1"></a>(iris_predictions</span>
<span id="cb53-2"><a href="chapter-5.html#cb53-2" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">roc_curve</span>(<span class="at">truth =</span> setosa, .pred_TRUE) </span>
<span id="cb53-3"><a href="chapter-5.html#cb53-3" aria-hidden="true" tabindex="-1"></a>  <span class="sc">|&gt;</span> <span class="fu">autoplot</span>())</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
<p>The dotted diagonal line represents the probability of randomly guessing the correct
class, so you want to be as far from that line as possible! For a theoretical model
making perfect predictions, the curve would rise straight up the left side then across
the top. The <em>area under the curve</em> (AUC) is a value between 0 and 1 that provides a
quantitative measurement of the performance indicated by the ROC curve. The closer this
value is to 1, the better the model has performed.</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="chapter-5.html#cb54-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Define a set of metrics using the `yardstick` package</span></span>
<span id="cb54-2"><a href="chapter-5.html#cb54-2" aria-hidden="true" tabindex="-1"></a>eval_metrics <span class="ot">&lt;-</span> <span class="fu">metric_set</span>(ppv,    recall, specificity, accuracy, </span>
<span id="cb54-3"><a href="chapter-5.html#cb54-3" aria-hidden="true" tabindex="-1"></a>                           f_meas, kap,    roc_auc)</span>
<span id="cb54-4"><a href="chapter-5.html#cb54-4" aria-hidden="true" tabindex="-1"></a><span class="fu">eval_metrics</span>(</span>
<span id="cb54-5"><a href="chapter-5.html#cb54-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> iris_predictions, </span>
<span id="cb54-6"><a href="chapter-5.html#cb54-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">truth =</span> setosa, </span>
<span id="cb54-7"><a href="chapter-5.html#cb54-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">estimate =</span> .pred_class,</span>
<span id="cb54-8"><a href="chapter-5.html#cb54-8" aria-hidden="true" tabindex="-1"></a>  .pred_TRUE  <span class="co"># to be passed to `roc_auc()`</span></span>
<span id="cb54-9"><a href="chapter-5.html#cb54-9" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## # A tibble: 7 × 3
##   .metric     .estimator .estimate
##   &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;
## 1 ppv         binary         0.9  
## 2 recall      binary         0.938
## 3 specificity binary         0.951
## 4 accuracy    binary         0.947
## 5 f_meas      binary         0.918
## 6 kap         binary         0.879
## 7 roc_auc     binary         0.978</code></pre>
</div>
<div id="ch5-multinomial-logistic-regression" class="section level3 hasAnchor" number="5.4.2">
<h3><span class="header-section-number">5.4.2</span> Multinomial Logistic Regression<a href="chapter-5.html#ch5-multinomial-logistic-regression" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>When expanding our predictive value to predicting <em>all</em> classes of iris species:</p>
<p>Here we see that our relatively “un-tuned” model does a good job of identifying <em>setosa</em>
species but struggles a bit more with <em>versicolor</em> and <em>virginica</em> (due in large part to
our ‘tweaks’ to the data set). Each row represents the true class of the flower while
each column represents the predicted class of each flower. In a perfect world, we would
only have numbers on the diagonal. We can examine the same metrics as we did in the
binomial case:</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="chapter-5.html#cb56-1" aria-hidden="true" tabindex="-1"></a>eval_metrics <span class="ot">&lt;-</span> <span class="fu">metric_set</span>(ppv,    recall, specificity, accuracy, </span>
<span id="cb56-2"><a href="chapter-5.html#cb56-2" aria-hidden="true" tabindex="-1"></a>                           f_meas, kap,    roc_auc)</span>
<span id="cb56-3"><a href="chapter-5.html#cb56-3" aria-hidden="true" tabindex="-1"></a><span class="fu">eval_metrics</span>(</span>
<span id="cb56-4"><a href="chapter-5.html#cb56-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> iris_predictions, </span>
<span id="cb56-5"><a href="chapter-5.html#cb56-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">truth =</span> Species, </span>
<span id="cb56-6"><a href="chapter-5.html#cb56-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">estimate =</span> .pred_class, </span>
<span id="cb56-7"><a href="chapter-5.html#cb56-7" aria-hidden="true" tabindex="-1"></a>  .pred_setosa,      <span class="co"># to be passed to `roc_auc()`</span></span>
<span id="cb56-8"><a href="chapter-5.html#cb56-8" aria-hidden="true" tabindex="-1"></a>  .pred_versicolor,  <span class="co"># / /</span></span>
<span id="cb56-9"><a href="chapter-5.html#cb56-9" aria-hidden="true" tabindex="-1"></a>  .pred_virginica    <span class="co"># /</span></span>
<span id="cb56-10"><a href="chapter-5.html#cb56-10" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## # A tibble: 7 × 3
##   .metric     .estimator .estimate
##   &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt;
## 1 ppv         macro          0.922
## 2 recall      macro          0.921
## 3 specificity macro          0.960
## 4 accuracy    multiclass     0.92 
## 5 f_meas      macro          0.921
## 6 kap         multiclass     0.880
## 7 roc_auc     hand_till      0.986</code></pre>
</div>
</div>
<div id="ch5-example" class="section level2 hasAnchor" number="5.5">
<h2><span class="header-section-number">5.5</span> Example<a href="chapter-5.html#ch5-example" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><em>This section is currently under construction</em></p>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="5">
<li id="fn5"><p>Definition from <a href="https://en.wikipedia.org/wiki/Confusion_matrix">Wikipedia</a>.<a href="chapter-5.html#fnref5" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="chapter-4.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="references.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/chapters/ch05-logistic-regression.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
